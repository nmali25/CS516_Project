{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install aif360['all']"
      ],
      "metadata": {
        "id": "_msJ5E_gklwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "de45c54c-e6a9-4d6a-bb66-f39cfa407922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aif360[all]\n",
            "  Downloading aif360-0.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (1.14.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (3.10.0)\n",
            "Collecting skorch (from aif360[all])\n",
            "  Downloading skorch-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jupyter (from aif360[all])\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting sphinx-rtd-theme (from aif360[all])\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting igraph[plotting] (from aif360[all])\n",
            "  Downloading igraph-0.11.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting lime (from aif360[all])\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (4.67.1)\n",
            "Collecting fairlearn~=0.7 (from aif360[all])\n",
            "  Downloading fairlearn-0.12.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting colorama (from aif360[all])\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: tensorflow>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (2.18.0)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (8.2.3)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (0.23.4)\n",
            "Collecting inFairness>=0.2.2 (from aif360[all])\n",
            "  Downloading inFairness-0.2.3-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting pytest-cov>=2.8.1 (from aif360[all])\n",
            "  Downloading pytest_cov-6.1.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting ipympl (from aif360[all])\n",
            "  Downloading ipympl-0.9.7-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (2.6.0+cu124)\n",
            "Requirement already satisfied: jinja2>3.1.0 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (3.1.6)\n",
            "Collecting adversarial-robustness-toolbox>=1.0.0 (from aif360[all])\n",
            "  Downloading adversarial_robustness_toolbox-1.19.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting BlackBoxAuditing (from aif360[all])\n",
            "  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (0.13.2)\n",
            "Requirement already satisfied: rpy2 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (3.5.17)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (4.5.0)\n",
            "Requirement already satisfied: pytest>=3.5 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (8.3.5)\n",
            "Collecting pot (from aif360[all])\n",
            "  Downloading POT-0.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Requirement already satisfied: cvxpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (1.6.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360[all]) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360[all]) (75.2.0)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.0->aif360[all]) (1.0.3)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.0->aif360[all]) (0.10.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.0->aif360[all]) (3.2.7.post2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>3.1.0->aif360[all]) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->aif360[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->aif360[all]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->aif360[all]) (2025.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=3.5->aif360[all]) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest>=3.5->aif360[all]) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=3.5->aif360[all]) (1.5.0)\n",
            "Collecting coverage>=7.5 (from coverage[toml]>=7.5->pytest-cov>=2.8.1->aif360[all])\n",
            "  Downloading coverage-7.8.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->aif360[all]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->aif360[all]) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (2.32.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->aif360[all])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->aif360[all])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->aif360[all])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->aif360[all])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->aif360[all])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->aif360[all])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->aif360[all])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->aif360[all])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->aif360[all])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->aif360[all])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->aif360[all]) (1.3.0)\n",
            "Collecting texttable>=1.6.2 (from igraph[plotting]; extra == \"all\"->aif360[all])\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting cairocffi>=1.2.0 (from igraph[plotting]; extra == \"all\"->aif360[all])\n",
            "  Downloading cairocffi-1.7.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: ipython<10 in /usr/local/lib/python3.11/dist-packages (from ipympl->aif360[all]) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.11/dist-packages (from ipympl->aif360[all]) (7.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from ipympl->aif360[all]) (11.1.0)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.11/dist-packages (from ipympl->aif360[all]) (5.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360[all]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360[all]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360[all]) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360[all]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360[all]) (3.2.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter->aif360[all]) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter->aif360[all]) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter->aif360[all]) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter->aif360[all]) (6.17.1)\n",
            "Collecting jupyterlab (from jupyter->aif360[all])\n",
            "  Downloading jupyterlab-4.4.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime->aif360[all]) (0.25.2)\n",
            "Requirement already satisfied: cffi>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from rpy2->aif360[all]) (1.17.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from rpy2->aif360[all]) (5.3.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch->aif360[all]) (0.9.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.0.0)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.18.0)\n",
            "Requirement already satisfied: docutils<0.22,>=0.20 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (0.21.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (3.1.0)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->aif360[all])\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.13.1->aif360[all]) (0.45.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.15.1->rpy2->aif360[all]) (2.22)\n",
            "Collecting jedi>=0.16 (from ipython<10->ipympl->aif360[all])\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->aif360[all]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->aif360[all]) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->aif360[all]) (3.0.51)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->aif360[all]) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->aif360[all]) (4.9.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (3.0.14)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->aif360[all]) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->aif360[all]) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->aif360[all]) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->aif360[all]) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->aif360[all]) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->aif360[all]) (6.4.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=1.13.1->aif360[all]) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=1.13.1->aif360[all]) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=1.13.1->aif360[all]) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=1.13.1->aif360[all]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=1.13.1->aif360[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=1.13.1->aif360[all]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=1.13.1->aif360[all]) (2025.1.31)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime->aif360[all]) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime->aif360[all]) (2025.3.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime->aif360[all]) (0.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.13.1->aif360[all]) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.13.1->aif360[all]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.13.1->aif360[all]) (3.1.3)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter->aif360[all])\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->aif360[all]) (0.28.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->aif360[all]) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter->aif360[all])\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter->aif360[all])\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter->aif360[all])\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->aif360[all]) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->aif360[all]) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->aif360[all]) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->aif360[all]) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->aif360[all]) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->aif360[all]) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->aif360[all]) (1.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->aif360[all]) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->aif360[all]) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->aif360[all]) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->aif360[all]) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter->aif360[all]) (0.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython<10->ipympl->aif360[all]) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->jupyter->aif360[all]) (4.3.7)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel->jupyter->aif360[all])\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all]) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter->aif360[all]) (21.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->aif360[all]) (0.4)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->aif360[all]) (4.23.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter->aif360[all]) (2.21.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython<10->ipympl->aif360[all]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<10->ipympl->aif360[all]) (0.2.13)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter->aif360[all]) (2.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=1.13.1->aif360[all]) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter->aif360[all]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->aif360[all]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->aif360[all]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->aif360[all]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->aif360[all]) (0.24.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all]) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=1.13.1->aif360[all]) (0.1.2)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all]) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all]) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading adversarial_robustness_toolbox-1.19.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fairlearn-0.12.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inFairness-0.2.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading POT-0.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_cov-6.1.1-py3-none-any.whl (23 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aif360-0.6.1-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.7/259.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading ipympl-0.9.7-py3-none-any.whl (515 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.7/515.7 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading skorch-1.1.0-py3-none-any.whl (228 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cairocffi-1.7.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coverage-7.8.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.0/244.0 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading igraph-0.11.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.4.1-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m128.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: BlackBoxAuditing, lime\n",
            "  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394756 sha256=a657135753741763dbcac0398fbbd53aa5483eb9ea18c1047d230e2449b3f2b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/8c/03/073e80e604151fb4cdc68b2e56a97f338d7723e4a4ab5e3823\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=12645bd0103872484572004c8c09df6f07737f6910c6bb1036e70eae8c1aded9\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built BlackBoxAuditing lime\n",
            "Installing collected packages: texttable, uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, json5, jedi, igraph, fqdn, coverage, colorama, async-lru, pot, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jupyter-server-terminals, jupyter-client, cairocffi, arrow, sphinxcontrib-jquery, skorch, pytest-cov, nvidia-cusolver-cu12, lime, isoduration, fairlearn, BlackBoxAuditing, aif360, adversarial-robustness-toolbox, sphinx-rtd-theme, jupyter-events, inFairness, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter, ipympl\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "Successfully installed BlackBoxAuditing-0.1.54 adversarial-robustness-toolbox-1.19.1 aif360-0.6.1 arrow-1.3.0 async-lru-2.0.5 cairocffi-1.7.1 colorama-0.4.6 coverage-7.8.0 fairlearn-0.12.0 fqdn-1.5.1 igraph-0.11.8 inFairness-0.2.3 ipympl-0.9.7 isoduration-20.11.0 jedi-0.19.2 json5-0.12.0 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.1 jupyterlab-server-2.27.3 lime-0.2.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 overrides-7.7.0 pot-0.9.5 pytest-cov-6.1.1 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 skorch-1.1.0 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1 texttable-1.7.0 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fairlearn"
      ],
      "metadata": {
        "id": "gjj8CEZFHwnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Core Python Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Scikit-Learn: Preprocessing, Modeling, Evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# AIF360: Datasets and Metrics\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import ClassificationMetric\n",
        "\n",
        "# AIF360: Preprocessing Algorithms\n",
        "from aif360.algorithms.preprocessing import (\n",
        "    Reweighing,\n",
        "    DisparateImpactRemover,\n",
        "    LFR\n",
        ")\n",
        "\n",
        "# AIF360: In-processing Algorithms\n",
        "from aif360.algorithms.inprocessing import (\n",
        "    MetaFairClassifier,\n",
        "    GerryFairClassifier,\n",
        "    PrejudiceRemover,\n",
        "    ExponentiatedGradientReduction,\n",
        "    GridSearchReduction,\n",
        "    ARTClassifier,\n",
        "    AdversarialDebiasing\n",
        ")\n",
        "\n",
        "#AIF360: Post-processing Algorithms\n",
        "from aif360.algorithms.postprocessing import (\n",
        "    RejectOptionClassification,\n",
        "    CalibratedEqOddsPostprocessing,\n",
        "    EqOddsPostprocessing\n",
        ")\n",
        "\n",
        "# TensorFlow for AdversarialDebiasing\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n"
      ],
      "metadata": {
        "id": "T-7mVQc2UKuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data loading"
      ],
      "metadata": {
        "id": "MRMGxO9EIJva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_german_data():\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
        "    column_names = [\n",
        "        \"status\", \"duration\", \"credit_history\", \"purpose\", \"credit_amount\",\n",
        "        \"savings\", \"employment\", \"installment_rate\", \"personal_status\",\n",
        "        \"other_debtors\", \"residence_since\", \"property\", \"age\",\n",
        "        \"other_installment_plans\", \"housing\", \"number_credits\", \"job\",\n",
        "        \"people_liable\", \"telephone\", \"foreign_worker\", \"target\"\n",
        "    ]\n",
        "    df = pd.read_csv(url, sep=' ', header=None, names=column_names)\n",
        "\n",
        "    # Binary target: 1 for good, 0 for bad\n",
        "    df['target'] = df['target'].map({1: 1, 2: 0})\n",
        "\n",
        "    # Binary protected attribute: age >= 25 -> 1 (privileged), < 25 -> 0 (unprivileged)\n",
        "    df['age_binary'] = df['age'].apply(lambda x: 1 if x >= 25 else 0)\n",
        "\n",
        "    # One-hot encode categorical features\n",
        "    df_encoded = pd.get_dummies(df.drop(columns=['target', 'age_binary', 'age']), drop_first=True)\n",
        "\n",
        "    X = df_encoded\n",
        "    y = df['target']\n",
        "    protected = df['age_binary']\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    X_train, X_test, y_train, y_test, prot_train, prot_test = train_test_split(\n",
        "        X_scaled, y, protected, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, prot_train, prot_test\n"
      ],
      "metadata": {
        "id": "3KjeXIoWUsqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_german_credit_data():\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
        "    columns = [\n",
        "        \"status\", \"duration\", \"credit_history\", \"purpose\", \"credit_amount\",\n",
        "        \"savings\", \"employment\", \"installment_rate\", \"personal_status\",\n",
        "        \"other_debtors\", \"residence_since\", \"property\", \"age\",\n",
        "        \"other_installment_plans\", \"housing\", \"number_credits\", \"job\",\n",
        "        \"people_liable\", \"telephone\", \"foreign_worker\", \"target\"\n",
        "    ]\n",
        "    df = pd.read_csv(url, sep=' ', header=None, names=columns)\n",
        "    df['target'] = df['target'].map({1: 1, 2: 0})\n",
        "    df['age_binary'] = df['age'].apply(lambda x: 1 if x >= 25 else 0)\n",
        "\n",
        "    X_raw = df.drop(columns=['target', 'age', 'age_binary'])\n",
        "    y = df['target'].values\n",
        "    prot = df['age_binary'].values\n",
        "\n",
        "    return X_raw, y, prot\n",
        "\n",
        "def preprocess_data(X_raw, y, prot):\n",
        "    cat_cols = X_raw.select_dtypes(include='object').columns.tolist()\n",
        "    num_cols = X_raw.select_dtypes(exclude='object').columns.tolist()\n",
        "\n",
        "    X_raw_train, X_raw_test, y_train, y_test, prot_train, prot_test = train_test_split(\n",
        "        X_raw, y, prot, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
        "    X_train_cat = encoder.fit_transform(X_raw_train[cat_cols])\n",
        "    X_test_cat = encoder.transform(X_raw_test[cat_cols])\n",
        "\n",
        "    X_train_num = X_raw_train[num_cols].values\n",
        "    X_test_num = X_raw_test[num_cols].values\n",
        "\n",
        "    X_train = np.hstack((X_train_num, X_train_cat))\n",
        "    X_test = np.hstack((X_test_num, X_test_cat))\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, prot_train, prot_test"
      ],
      "metadata": {
        "id": "wYKZa7A-FVqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_german_credit_data_inprocess():\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
        "    columns = [\"status\", \"duration\", \"credit_history\", \"purpose\", \"credit_amount\",\n",
        "               \"savings\", \"employment\", \"installment_rate\", \"personal_status\",\n",
        "               \"other_debtors\", \"residence_since\", \"property\", \"age\",\n",
        "               \"other_installment_plans\", \"housing\", \"number_credits\", \"job\",\n",
        "               \"people_liable\", \"telephone\", \"foreign_worker\", \"target\"]\n",
        "\n",
        "    df = pd.read_csv(url, sep=' ', header=None, names=columns)\n",
        "    df['target'] = df['target'].map({1: 1, 2: 0})\n",
        "    df['age_binary'] = df['age'].apply(lambda x: 1 if x >= 25 else 0)\n",
        "\n",
        "    X_raw = df.drop(columns=['target', 'age', 'age_binary'])\n",
        "    y = df['target'].values\n",
        "    prot = df['age_binary'].values\n",
        "\n",
        "    X_train_raw, X_test_raw, y_train, y_test, prot_train, prot_test = train_test_split(\n",
        "        X_raw, y, prot, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    categorical_cols = X_raw.select_dtypes(include='object').columns.tolist()\n",
        "    numeric_cols = X_raw.select_dtypes(exclude='object').columns.tolist()\n",
        "\n",
        "    encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
        "    X_train_cat = encoder.fit_transform(X_train_raw[categorical_cols])\n",
        "    X_test_cat = encoder.transform(X_test_raw[categorical_cols])\n",
        "\n",
        "    X_train_num = X_train_raw[numeric_cols].values\n",
        "    X_test_num = X_test_raw[numeric_cols].values\n",
        "\n",
        "    X_train = np.hstack((X_train_num, X_train_cat))\n",
        "    X_test = np.hstack((X_test_num, X_test_cat))\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, prot_train, prot_test\n"
      ],
      "metadata": {
        "id": "GI7gpzv1IEuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Utility Functions"
      ],
      "metadata": {
        "id": "_ZsVhApdIFx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_baseline_model(X_train, y_train, sample_weight=None):\n",
        "    model = XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weight)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "KdUC91D_F3Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_fairness(y_true, y_pred, prot, X=None):\n",
        "    df = pd.DataFrame(np.hstack((X, y_true[:, None], prot[:, None])),\n",
        "                      columns=[f\"x{i}\" for i in range(X.shape[1])] + ['label', 'protected'])\n",
        "\n",
        "    dataset_true = BinaryLabelDataset(df=df,\n",
        "                                      label_names=[\"label\"],\n",
        "                                      protected_attribute_names=[\"protected\"],\n",
        "                                      favorable_label=1, unfavorable_label=0)\n",
        "\n",
        "    pred_dataset = dataset_true.copy()\n",
        "    pred_dataset.labels = y_pred.reshape(-1, 1)\n",
        "\n",
        "    metric = ClassificationMetric(dataset_true, pred_dataset,\n",
        "                                  privileged_groups=[{'protected': 1}],\n",
        "                                  unprivileged_groups=[{'protected': 0}])\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'disparate_impact': metric.disparate_impact(),\n",
        "        'statistical_parity_difference': metric.statistical_parity_difference(),\n",
        "        'equal_opportunity_difference': metric.equal_opportunity_difference()\n",
        "    }\n"
      ],
      "metadata": {
        "id": "UmXUc4HcF-mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test, prot_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    return evaluate_fairness(y_test, y_pred, prot_test, X_test)\n"
      ],
      "metadata": {
        "id": "h7DJ4vxXGAF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EwrdQgx2ea0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGboost\n",
        "X_train, X_test, y_train, y_test, prot_train, prot_test = load_and_preprocess_german_data()\n",
        "baseline_model = train_baseline_model(X_train, y_train)\n",
        "baseline_metrics = evaluate_model(baseline_model, X_test, y_test.to_numpy(), prot_test.to_numpy())\n",
        "\n",
        "baseline_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHXnaTnhVTlk",
        "outputId": "d8465c40-1fc7-4e8c-86e0-e5d5a87fee2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:46:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7033333333333334,\n",
              " 'disparate_impact': np.float64(0.8115043301614455),\n",
              " 'statistical_parity_difference': np.float64(-0.14826339248170883),\n",
              " 'equal_opportunity_difference': np.float64(-0.20484949832775923)}"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inprocess_results = {}"
      ],
      "metadata": {
        "id": "3LXrBhDvGhSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##disparate impact"
      ],
      "metadata": {
        "id": "0iFApi5gedu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_disparate_impact_remover(X_train, y_train, prot_train, repair_level=1.0):\n",
        "    df = pd.DataFrame(X_train)\n",
        "    df['target'] = y_train.values\n",
        "    df['protected'] = prot_train.values\n",
        "\n",
        "    dataset = BinaryLabelDataset(\n",
        "        favorable_label=1,\n",
        "        unfavorable_label=0,\n",
        "        df=df,\n",
        "        label_names=['target'],\n",
        "        protected_attribute_names=['protected']\n",
        "    )\n",
        "\n",
        "    dir_remover = DisparateImpactRemover(repair_level=repair_level)\n",
        "    repaired_dataset = dir_remover.fit_transform(dataset)\n",
        "\n",
        "    X_repaired = pd.DataFrame(repaired_dataset.features)\n",
        "    y_repaired = pd.Series(repaired_dataset.labels.ravel())\n",
        "    prot_repaired = pd.Series(repaired_dataset.protected_attributes.ravel())\n",
        "\n",
        "    return X_repaired, y_repaired, prot_repaired\n"
      ],
      "metadata": {
        "id": "SS_fT8YeVWIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Disparate Impact Remover to both train and test sets\n",
        "X_train_repaired, y_train_repaired, prot_train_repaired = apply_disparate_impact_remover(\n",
        "    pd.DataFrame(X_train), y_train, prot_train\n",
        ")\n",
        "\n",
        "X_test_repaired, y_test_repaired, prot_test_repaired = apply_disparate_impact_remover(\n",
        "    pd.DataFrame(X_test), y_test, prot_test\n",
        ")\n",
        "\n",
        "# Train on repaired training data\n",
        "fair_model = train_baseline_model(X_train_repaired, y_train_repaired)\n",
        "\n",
        "# Evaluate on repaired test data\n",
        "fair_metrics = evaluate_model(\n",
        "    fair_model,\n",
        "    X_test_repaired.to_numpy(),\n",
        "    y_test_repaired.to_numpy(),\n",
        "    prot_test_repaired.to_numpy()\n",
        ")\n",
        "inprocess_results['Disparate_Impact_Remover']=fair_metrics\n",
        "fair_metrics\n"
      ],
      "metadata": {
        "id": "DZTmaL0dXLss",
        "outputId": "7026c592-f44f-425d-c42e-4755cb292df9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:46:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7166666666666667,\n",
              " 'disparate_impact': np.float64(0.9916013437849943),\n",
              " 'statistical_parity_difference': np.float64(-0.006307291228660361),\n",
              " 'equal_opportunity_difference': np.float64(-0.07316053511705678)}"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##LFR"
      ],
      "metadata": {
        "id": "IM4Gsh0teXy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_lfr(X_train, y_train, prot_train):\n",
        "    df = pd.DataFrame(X_train)\n",
        "    df['target'] = y_train.values\n",
        "    df['protected'] = prot_train.values\n",
        "\n",
        "    dataset = BinaryLabelDataset(\n",
        "        favorable_label=1,\n",
        "        unfavorable_label=0,\n",
        "        df=df,\n",
        "        label_names=['target'],\n",
        "        protected_attribute_names=['protected']\n",
        "    )\n",
        "\n",
        "    lfr = LFR(unprivileged_groups=[{'protected': 0}],\n",
        "          privileged_groups=[{'protected': 1}],\n",
        "          k=10, Ax=0.01, Ay=1.0, Az=0.1, verbose=0)\n",
        "\n",
        "\n",
        "    lfr.fit(dataset)\n",
        "    transformed_dataset = lfr.transform(dataset)\n",
        "\n",
        "    X_transformed = pd.DataFrame(transformed_dataset.features)\n",
        "    y_transformed = pd.Series(transformed_dataset.labels.ravel())\n",
        "    prot_transformed = pd.Series(transformed_dataset.protected_attributes.ravel())\n",
        "\n",
        "    return X_transformed, y_transformed, prot_transformed, lfr\n"
      ],
      "metadata": {
        "id": "liLwxciLejD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lfr, y_train_lfr, prot_train_lfr, lfr_model = apply_lfr(pd.DataFrame(X_train), y_train, prot_train)\n"
      ],
      "metadata": {
        "id": "Dke6DdwRekky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique labels in y_train_lfr:\", np.unique(y_train_lfr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmmBlvSRfCjX",
        "outputId": "06d121df-34af-442c-93cb-c9ab38f76321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in y_train_lfr: [0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fair_lfr_model = train_baseline_model(X_train_lfr, y_train_lfr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy6VtAcQemhQ",
        "outputId": "58868270-8c95-41dd-f348-dabe44d8383b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:46:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply LFR transformation on test set\n",
        "df_test = pd.DataFrame(X_test)\n",
        "df_test['target'] = y_test.values\n",
        "df_test['protected'] = prot_test.values\n",
        "\n",
        "test_dataset = BinaryLabelDataset(\n",
        "    favorable_label=1,\n",
        "    unfavorable_label=0,\n",
        "    df=df_test,\n",
        "    label_names=['target'],\n",
        "    protected_attribute_names=['protected']\n",
        ")\n",
        "\n",
        "transformed_test_dataset = lfr_model.transform(test_dataset)\n",
        "\n",
        "X_test_lfr = pd.DataFrame(transformed_test_dataset.features)\n",
        "y_test_lfr = pd.Series(transformed_test_dataset.labels.ravel())\n",
        "prot_test_lfr = pd.Series(transformed_test_dataset.protected_attributes.ravel())\n",
        "\n",
        "# Evaluate\n",
        "fair_lfr_metrics = evaluate_model(\n",
        "    fair_lfr_model,\n",
        "    X_test_lfr.to_numpy(),\n",
        "    y_test_lfr.to_numpy(),\n",
        "    prot_test_lfr.to_numpy()\n",
        ")\n",
        "inprocess_results['LFR']=fair_lfr_metrics\n",
        "\n",
        "fair_lfr_metrics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhEjgCm3evMi",
        "outputId": "f509a12c-dbca-4777-b147-1a236bd6934b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/aif360/metrics/classification_metric.py:278: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
            "/usr/local/lib/python3.11/dist-packages/aif360/metrics/classification_metric.py:279: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9966666666666667,\n",
              " 'disparate_impact': np.float64(1.003968253968254),\n",
              " 'statistical_parity_difference': np.float64(0.0039525691699604515),\n",
              " 'equal_opportunity_difference': np.float64(0.0)}"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reweighing"
      ],
      "metadata": {
        "id": "Maxq0HlAHAEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_reweighing(X_train, y_train, prot_train):\n",
        "    df_train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1), prot_train.reshape(-1, 1))),\n",
        "                            columns=[f\"x{i}\" for i in range(X_train.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_train = BinaryLabelDataset(\n",
        "        favorable_label=1,\n",
        "        unfavorable_label=0,\n",
        "        df=df_train,\n",
        "        label_names=[\"label\"],\n",
        "        protected_attribute_names=[\"protected\"]\n",
        "    )\n",
        "    RW = Reweighing(unprivileged_groups=[{'protected': 0}], privileged_groups=[{'protected': 1}])\n",
        "    bld_rw = RW.fit_transform(bld_train)\n",
        "\n",
        "    return bld_rw.features, bld_rw.labels.ravel(), bld_rw.instance_weights\n"
      ],
      "metadata": {
        "id": "7CKRSQlnCnT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test, prot_train, prot_test = preprocess_data(*load_german_credit_data())\n",
        "\n",
        "X_rw, y_rw, sample_weights = apply_reweighing(X_train, y_train, prot_train)\n",
        "\n",
        "expected_num_features = X_rw.shape[1]\n",
        "\n",
        "if X_test.shape[1] < expected_num_features:\n",
        "    padding = expected_num_features - X_test.shape[1]\n",
        "    X_test_aligned = np.hstack((X_test, np.zeros((X_test.shape[0], padding))))\n",
        "elif X_test.shape[1] > expected_num_features:\n",
        "    X_test_aligned = X_test[:, :expected_num_features]\n",
        "else:\n",
        "    X_test_aligned = X_test\n",
        "\n",
        "model_rw = train_baseline_model(X_rw, y_rw, sample_weight=sample_weights)\n",
        "\n",
        "reweighing_metric = evaluate_model(model_rw, X_test_aligned, y_test, prot_test)\n",
        "\n",
        "inprocess_results['reweighing'] = reweighing_metric\n",
        "reweighing_metric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GygXVrOmDCHX",
        "outputId": "7e46ebe7-755d-42da-dd27-c2f459ea461c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:46:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.72,\n",
              " 'disparate_impact': np.float64(0.8646235255208906),\n",
              " 'statistical_parity_difference': np.float64(-0.10327138171726524),\n",
              " 'equal_opportunity_difference': np.float64(-0.16095317725752512)}"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model, metrics in inprocess_results.items():\n",
        "    print(f\"🔹 {model}\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMCZUNH3HsQG",
        "outputId": "11b75c70-ba83-4fcd-d5a7-7488a80bc960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Disparate_Impact_Remover\n",
            "  accuracy: 0.7167\n",
            "  disparate_impact: 0.9916\n",
            "  statistical_parity_difference: -0.0063\n",
            "  equal_opportunity_difference: -0.0732\n",
            "\n",
            "🔹 LFR\n",
            "  accuracy: 0.9967\n",
            "  disparate_impact: 1.0040\n",
            "  statistical_parity_difference: 0.0040\n",
            "  equal_opportunity_difference: 0.0000\n",
            "\n",
            "🔹 reweighing\n",
            "  accuracy: 0.7200\n",
            "  disparate_impact: 0.8646\n",
            "  statistical_parity_difference: -0.1033\n",
            "  equal_opportunity_difference: -0.1610\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Inprocess"
      ],
      "metadata": {
        "id": "ckjyZeplrqHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test, prot_train, prot_test = load_german_credit_data_inprocess()\n",
        "results = {}"
      ],
      "metadata": {
        "id": "OvO0R5sPI5Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gerryfair(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    df_train = pd.DataFrame(np.hstack((X_train, y_train[:, None], prot_train[:, None])),\n",
        "                            columns=[f\"x{i}\" for i in range(X_train.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_train = BinaryLabelDataset(df=df_train, label_names=[\"label\"], protected_attribute_names=[\"protected\"],\n",
        "                                   favorable_label=1, unfavorable_label=0)\n",
        "\n",
        "    df_test = pd.DataFrame(np.hstack((X_test, y_test[:, None], prot_test[:, None])),\n",
        "                           columns=[f\"x{i}\" for i in range(X_test.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_test = BinaryLabelDataset(df=df_test, label_names=[\"label\"], protected_attribute_names=[\"protected\"],\n",
        "                                  favorable_label=1, unfavorable_label=0)\n",
        "\n",
        "    clf = GerryFairClassifier(C=100, printflag=False, gamma=0.005, fairness_def='FP', max_iters=50)\n",
        "    clf.fit(bld_train)\n",
        "    pred = clf.predict(bld_test)\n",
        "\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)\n"
      ],
      "metadata": {
        "id": "TUllqmP6xbgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['GerryFair'] = train_gerryfair(X_train, y_train, prot_train, X_test, y_test, prot_test)\n"
      ],
      "metadata": {
        "id": "zhCuFVZBI6j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_prejudice_remover(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    df_train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1), prot_train.reshape(-1, 1))),\n",
        "                            columns=[f\"x{i}\" for i in range(X_train.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_train = BinaryLabelDataset(df=df_train,\n",
        "                                   label_names=[\"label\"],\n",
        "                                   protected_attribute_names=[\"protected\"],\n",
        "                                   favorable_label=1,\n",
        "                                   unfavorable_label=0)\n",
        "\n",
        "    df_test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1), prot_test.reshape(-1, 1))),\n",
        "                           columns=[f\"x{i}\" for i in range(X_test.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_test = BinaryLabelDataset(df=df_test,\n",
        "                                  label_names=[\"label\"],\n",
        "                                  protected_attribute_names=[\"protected\"],\n",
        "                                  favorable_label=1,\n",
        "                                  unfavorable_label=0)\n",
        "\n",
        "    clf = PrejudiceRemover(sensitive_attr=\"protected\", eta=25.0)\n",
        "    clf.fit(bld_train)\n",
        "    pred = clf.predict(bld_test)\n",
        "\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)\n"
      ],
      "metadata": {
        "id": "xSmVTFLlxdBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['PrejudiceRemover'] = train_prejudice_remover(X_train, y_train, prot_train, X_test, y_test, prot_test)\n"
      ],
      "metadata": {
        "id": "emuzoR6AJAeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_expgrad(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    df_train = pd.DataFrame(np.hstack((X_train, y_train[:, None], prot_train[:, None])),\n",
        "                            columns=[f\"x{i}\" for i in range(X_train.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_train = BinaryLabelDataset(df=df_train,\n",
        "                                   label_names=[\"label\"],\n",
        "                                   protected_attribute_names=[\"protected\"],\n",
        "                                   favorable_label=1,\n",
        "                                   unfavorable_label=0)\n",
        "\n",
        "    df_test = pd.DataFrame(np.hstack((X_test, y_test[:, None], prot_test[:, None])),\n",
        "                           columns=[f\"x{i}\" for i in range(X_test.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_test = BinaryLabelDataset(df=df_test,\n",
        "                                  label_names=[\"label\"],\n",
        "                                  protected_attribute_names=[\"protected\"],\n",
        "                                  favorable_label=1,\n",
        "                                  unfavorable_label=0)\n",
        "\n",
        "    expgrad = ExponentiatedGradientReduction(\n",
        "        estimator=LogisticRegression(solver='liblinear'),\n",
        "        constraints=\"DemographicParity\"\n",
        "    )\n",
        "    expgrad.fit(bld_train)\n",
        "\n",
        "    pred = expgrad.predict(bld_test)\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)\n"
      ],
      "metadata": {
        "id": "lJff7KFSxeik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['ExponentiatedGradient'] = train_expgrad(X_train, y_train, prot_train, X_test, y_test, prot_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVSugHebJCdn",
        "outputId": "153e80c8-8ad4-41c3-f05c-5beed0b0fe11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gridsearch(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    df_train = pd.DataFrame(np.hstack((X_train, y_train[:, None], prot_train[:, None])),\n",
        "                            columns=[f\"x{i}\" for i in range(X_train.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_train = BinaryLabelDataset(df=df_train,\n",
        "                                   label_names=[\"label\"],\n",
        "                                   protected_attribute_names=[\"protected\"],\n",
        "                                   favorable_label=1,\n",
        "                                   unfavorable_label=0)\n",
        "\n",
        "    df_test = pd.DataFrame(np.hstack((X_test, y_test[:, None], prot_test[:, None])),\n",
        "                           columns=[f\"x{i}\" for i in range(X_test.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_test = BinaryLabelDataset(df=df_test,\n",
        "                                  label_names=[\"label\"],\n",
        "                                  protected_attribute_names=[\"protected\"],\n",
        "                                  favorable_label=1,\n",
        "                                  unfavorable_label=0)\n",
        "\n",
        "    grid = GridSearchReduction(\n",
        "        estimator=LogisticRegression(solver='liblinear'),\n",
        "        constraints=\"DemographicParity\"\n",
        "    )\n",
        "    grid.fit(bld_train)\n",
        "\n",
        "    pred = grid.predict(bld_test)\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)\n"
      ],
      "metadata": {
        "id": "paNuPAJlySlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['GridSearch'] = train_gridsearch(X_train, y_train, prot_train, X_test, y_test, prot_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njMrq0s_xgSb",
        "outputId": "4ad1c533-1395-4ffe-eb28-7ae15f6ca923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.disable_eager_execution()  # Required for TF1 compatibility in AIF360\n",
        "\n",
        "def train_adversarial_debiasing(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    # Train data\n",
        "    tf.reset_default_graph()\n",
        "    df_train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1), prot_train.reshape(-1, 1))),\n",
        "                            columns=[f\"x{i}\" for i in range(X_train.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_train = BinaryLabelDataset(df=df_train,\n",
        "                                   label_names=[\"label\"],\n",
        "                                   protected_attribute_names=[\"protected\"],\n",
        "                                   favorable_label=1,\n",
        "                                   unfavorable_label=0)\n",
        "\n",
        "    # Test data\n",
        "    df_test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1), prot_test.reshape(-1, 1))),\n",
        "                           columns=[f\"x{i}\" for i in range(X_test.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_test = BinaryLabelDataset(df=df_test,\n",
        "                                  label_names=[\"label\"],\n",
        "                                  protected_attribute_names=[\"protected\"],\n",
        "                                  favorable_label=1,\n",
        "                                  unfavorable_label=0)\n",
        "\n",
        "    # TensorFlow session\n",
        "    sess = tf.Session()\n",
        "\n",
        "    clf = AdversarialDebiasing(\n",
        "        privileged_groups=[{'protected': 1}],\n",
        "        unprivileged_groups=[{'protected': 0}],\n",
        "        scope_name='adv_debiasing',\n",
        "        sess=sess,\n",
        "        num_epochs=50,\n",
        "        batch_size=64,\n",
        "        debias=True\n",
        "    )\n",
        "\n",
        "    clf.fit(bld_train)\n",
        "    pred = clf.predict(bld_test)\n",
        "\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)\n"
      ],
      "metadata": {
        "id": "H8z8KFCAzLIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['AdversarialDebiasing'] = train_adversarial_debiasing(X_train, y_train, prot_train, X_test, y_test, prot_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA25q1kMzMcd",
        "outputId": "590633aa-da8c-4847-c896-43680ef243ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 0.804562; batch adversarial loss: 0.450733\n",
            "epoch 1; iter: 0; batch classifier loss: 0.581346; batch adversarial loss: 0.450953\n",
            "epoch 2; iter: 0; batch classifier loss: 0.415577; batch adversarial loss: 0.432432\n",
            "epoch 3; iter: 0; batch classifier loss: 0.411867; batch adversarial loss: 0.476176\n",
            "epoch 4; iter: 0; batch classifier loss: 0.418556; batch adversarial loss: 0.441483\n",
            "epoch 5; iter: 0; batch classifier loss: 0.405587; batch adversarial loss: 0.479499\n",
            "epoch 6; iter: 0; batch classifier loss: 0.444162; batch adversarial loss: 0.529955\n",
            "epoch 7; iter: 0; batch classifier loss: 0.454269; batch adversarial loss: 0.545939\n",
            "epoch 8; iter: 0; batch classifier loss: 0.396039; batch adversarial loss: 0.443662\n",
            "epoch 9; iter: 0; batch classifier loss: 0.365126; batch adversarial loss: 0.493021\n",
            "epoch 10; iter: 0; batch classifier loss: 0.356113; batch adversarial loss: 0.421430\n",
            "epoch 11; iter: 0; batch classifier loss: 0.465698; batch adversarial loss: 0.425030\n",
            "epoch 12; iter: 0; batch classifier loss: 0.485759; batch adversarial loss: 0.466264\n",
            "epoch 13; iter: 0; batch classifier loss: 0.358717; batch adversarial loss: 0.382526\n",
            "epoch 14; iter: 0; batch classifier loss: 0.400853; batch adversarial loss: 0.466811\n",
            "epoch 15; iter: 0; batch classifier loss: 0.341185; batch adversarial loss: 0.394035\n",
            "epoch 16; iter: 0; batch classifier loss: 0.265122; batch adversarial loss: 0.403166\n",
            "epoch 17; iter: 0; batch classifier loss: 0.331425; batch adversarial loss: 0.397423\n",
            "epoch 18; iter: 0; batch classifier loss: 0.330884; batch adversarial loss: 0.452441\n",
            "epoch 19; iter: 0; batch classifier loss: 0.358202; batch adversarial loss: 0.600653\n",
            "epoch 20; iter: 0; batch classifier loss: 0.326877; batch adversarial loss: 0.422113\n",
            "epoch 21; iter: 0; batch classifier loss: 0.312726; batch adversarial loss: 0.524452\n",
            "epoch 22; iter: 0; batch classifier loss: 0.291284; batch adversarial loss: 0.516682\n",
            "epoch 23; iter: 0; batch classifier loss: 0.351326; batch adversarial loss: 0.460626\n",
            "epoch 24; iter: 0; batch classifier loss: 0.286881; batch adversarial loss: 0.510897\n",
            "epoch 25; iter: 0; batch classifier loss: 0.390229; batch adversarial loss: 0.596436\n",
            "epoch 26; iter: 0; batch classifier loss: 0.292378; batch adversarial loss: 0.393963\n",
            "epoch 27; iter: 0; batch classifier loss: 0.281633; batch adversarial loss: 0.565113\n",
            "epoch 28; iter: 0; batch classifier loss: 0.244493; batch adversarial loss: 0.459198\n",
            "epoch 29; iter: 0; batch classifier loss: 0.265593; batch adversarial loss: 0.602635\n",
            "epoch 30; iter: 0; batch classifier loss: 0.168625; batch adversarial loss: 0.463281\n",
            "epoch 31; iter: 0; batch classifier loss: 0.240328; batch adversarial loss: 0.502589\n",
            "epoch 32; iter: 0; batch classifier loss: 0.221241; batch adversarial loss: 0.482245\n",
            "epoch 33; iter: 0; batch classifier loss: 0.239821; batch adversarial loss: 0.385197\n",
            "epoch 34; iter: 0; batch classifier loss: 0.250945; batch adversarial loss: 0.489910\n",
            "epoch 35; iter: 0; batch classifier loss: 0.151611; batch adversarial loss: 0.458707\n",
            "epoch 36; iter: 0; batch classifier loss: 0.264070; batch adversarial loss: 0.325272\n",
            "epoch 37; iter: 0; batch classifier loss: 0.174056; batch adversarial loss: 0.382399\n",
            "epoch 38; iter: 0; batch classifier loss: 0.228540; batch adversarial loss: 0.405158\n",
            "epoch 39; iter: 0; batch classifier loss: 0.133678; batch adversarial loss: 0.398594\n",
            "epoch 40; iter: 0; batch classifier loss: 0.171068; batch adversarial loss: 0.399980\n",
            "epoch 41; iter: 0; batch classifier loss: 0.263927; batch adversarial loss: 0.520434\n",
            "epoch 42; iter: 0; batch classifier loss: 0.208420; batch adversarial loss: 0.429147\n",
            "epoch 43; iter: 0; batch classifier loss: 0.150634; batch adversarial loss: 0.499934\n",
            "epoch 44; iter: 0; batch classifier loss: 0.161342; batch adversarial loss: 0.416989\n",
            "epoch 45; iter: 0; batch classifier loss: 0.131544; batch adversarial loss: 0.448372\n",
            "epoch 46; iter: 0; batch classifier loss: 0.193131; batch adversarial loss: 0.361339\n",
            "epoch 47; iter: 0; batch classifier loss: 0.173349; batch adversarial loss: 0.395105\n",
            "epoch 48; iter: 0; batch classifier loss: 0.197187; batch adversarial loss: 0.582792\n",
            "epoch 49; iter: 0; batch classifier loss: 0.200372; batch adversarial loss: 0.369635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fairness Evaluation Across Compatible AIF360 In-processing Algorithms\\n\")\n",
        "for model, metrics in results.items():\n",
        "    print(f\"🔹 {model}\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        print(f\"  {metric_name}: {value:.4f}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCfZUuo63kQ6",
        "outputId": "926a443e-adb7-4333-913d-53f7464b02a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fairness Evaluation Across Compatible AIF360 In-processing Algorithms\n",
            "\n",
            "🔹 GerryFair\n",
            "  accuracy: 0.7500\n",
            "  disparate_impact: 0.8344\n",
            "  statistical_parity_difference: -0.1309\n",
            "  equal_opportunity_difference: -0.1605\n",
            "\n",
            "🔹 PrejudiceRemover\n",
            "  accuracy: 0.7200\n",
            "  disparate_impact: 1.0320\n",
            "  statistical_parity_difference: 0.0244\n",
            "  equal_opportunity_difference: -0.0017\n",
            "\n",
            "🔹 ExponentiatedGradient\n",
            "  accuracy: 0.7733\n",
            "  disparate_impact: 1.0331\n",
            "  statistical_parity_difference: 0.0259\n",
            "  equal_opportunity_difference: 0.0263\n",
            "\n",
            "🔹 GridSearch\n",
            "  accuracy: 0.7633\n",
            "  disparate_impact: 1.0177\n",
            "  statistical_parity_difference: 0.0140\n",
            "  equal_opportunity_difference: 0.0263\n",
            "\n",
            "🔹 AdversarialDebiasing\n",
            "  accuracy: 0.7233\n",
            "  disparate_impact: 1.1057\n",
            "  statistical_parity_difference: 0.0773\n",
            "  equal_opportunity_difference: 0.0146\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#postprocessing"
      ],
      "metadata": {
        "id": "z5hWBXLxJMAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test, prot_train, prot_test = load_german_credit_data_inprocess()\n",
        "post_results = {}"
      ],
      "metadata": {
        "id": "jdC4dnm-JvEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_roc_postprocessing_with_xgb(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    model = train_baseline_model(X_train, y_train)\n",
        "\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    bld_test = BinaryLabelDataset(\n",
        "        favorable_label=1,\n",
        "        unfavorable_label=0,\n",
        "        df=pd.DataFrame(np.hstack((X_test, y_test[:, None], prot_test[:, None])),\n",
        "                        columns=[f'x{i}' for i in range(X_test.shape[1])] + ['label', 'protected']),\n",
        "        label_names=['label'],\n",
        "        protected_attribute_names=['protected']\n",
        "    )\n",
        "\n",
        "    bld_pred = bld_test.copy()\n",
        "    bld_pred.scores = y_prob.reshape(-1, 1)\n",
        "    bld_pred.labels = y_pred.reshape(-1, 1)\n",
        "\n",
        "    roc = RejectOptionClassification(\n",
        "        unprivileged_groups=[{'protected': 0}],\n",
        "        privileged_groups=[{'protected': 1}],\n",
        "        low_class_thresh=0.01, high_class_thresh=0.99,\n",
        "        num_class_thresh=100, num_ROC_margin=50,\n",
        "        metric_name=\"Statistical parity difference\",\n",
        "        metric_ub=0.05, metric_lb=-0.05\n",
        "    )\n",
        "    roc = roc.fit(bld_test, bld_pred)\n",
        "    pred = roc.predict(bld_pred)\n",
        "\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)\n"
      ],
      "metadata": {
        "id": "KAaGOOMv3ssO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_results['RejectOptionClassification'] = train_roc_postprocessing_with_xgb(X_train, y_train, prot_train, X_test, y_test, prot_test)\n"
      ],
      "metadata": {
        "id": "5khEknevMU9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_calibrated_eq_odds_with_xgb(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    model = train_baseline_model(X_train, y_train)\n",
        "\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    bld_test = BinaryLabelDataset(\n",
        "        favorable_label=1,\n",
        "        unfavorable_label=0,\n",
        "        df=pd.DataFrame(np.hstack((X_test, y_test[:, None], prot_test[:, None])),\n",
        "                        columns=[f'x{i}' for i in range(X_test.shape[1])] + ['label', 'protected']),\n",
        "        label_names=['label'],\n",
        "        protected_attribute_names=['protected']\n",
        "    )\n",
        "\n",
        "    bld_pred = bld_test.copy()\n",
        "    bld_pred.scores = y_prob.reshape(-1, 1)\n",
        "\n",
        "    ceo = CalibratedEqOddsPostprocessing(\n",
        "        privileged_groups=[{'protected': 1}],\n",
        "        unprivileged_groups=[{'protected': 0}],\n",
        "        cost_constraint=\"fnr\",\n",
        "        seed=42\n",
        "    )\n",
        "    ceo = ceo.fit(bld_test, bld_pred)\n",
        "    pred = ceo.predict(bld_pred)\n",
        "\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)\n"
      ],
      "metadata": {
        "id": "4-lEz-kD6JUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_results['CalibratedEqOdds'] = train_calibrated_eq_odds_with_xgb(X_train, y_train, prot_train, X_test, y_test, prot_test)\n"
      ],
      "metadata": {
        "id": "1AunQ9VNMWxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_equalized_odds_with_xgb(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    model = train_baseline_model(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    bld_test = BinaryLabelDataset(\n",
        "        favorable_label=1,\n",
        "        unfavorable_label=0,\n",
        "        df=pd.DataFrame(np.hstack((X_test, y_test[:, None], prot_test[:, None])),\n",
        "                        columns=[f'x{i}' for i in range(X_test.shape[1])] + ['label', 'protected']),\n",
        "        label_names=['label'],\n",
        "        protected_attribute_names=['protected']\n",
        "    )\n",
        "\n",
        "    bld_pred = bld_test.copy()\n",
        "    bld_pred.labels = y_pred.reshape(-1, 1)\n",
        "\n",
        "    eq = EqOddsPostprocessing(\n",
        "        privileged_groups=[{'protected': 1}],\n",
        "        unprivileged_groups=[{'protected': 0}]\n",
        "    )\n",
        "    eq = eq.fit(bld_test, bld_pred)\n",
        "    pred = eq.predict(bld_pred)\n",
        "\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)\n"
      ],
      "metadata": {
        "id": "SjdA2g9P6LWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_results['EqualizedOdds'] = train_equalized_odds_with_xgb(X_train, y_train, prot_train, X_test, y_test, prot_test)"
      ],
      "metadata": {
        "id": "jDYTrQqF6Opo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model, metrics in post_results.items():\n",
        "    print(f\"🔹 {model}\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxj5oi7v6Y5a",
        "outputId": "ee900ad8-78f5-4d4f-afb7-48ff4ed91b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 RejectOptionClassification\n",
            "  accuracy: 0.7533\n",
            "  disparate_impact: 1.0525\n",
            "  statistical_parity_difference: 0.0372\n",
            "  equal_opportunity_difference: 0.0146\n",
            "\n",
            "🔹 CalibratedEqOdds\n",
            "  accuracy: 0.7067\n",
            "  disparate_impact: 0.6596\n",
            "  statistical_parity_difference: -0.3404\n",
            "  equal_opportunity_difference: -0.2692\n",
            "\n",
            "🔹 EqualizedOdds\n",
            "  accuracy: 0.6167\n",
            "  disparate_impact: 0.9590\n",
            "  statistical_parity_difference: -0.0282\n",
            "  equal_opportunity_difference: 0.0188\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AHL-3AJmLOdv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}