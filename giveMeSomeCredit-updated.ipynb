{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install aif360['all']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLRl_OXUi2Xf",
        "outputId": "24b1b9b7-c440-4e2e-e6aa-d7cc6978d8d4"
      },
      "id": "QLRl_OXUi2Xf",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aif360[all]\n",
            "  Downloading aif360-0.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (1.15.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (3.10.0)\n",
            "Collecting skorch (from aif360[all])\n",
            "  Downloading skorch-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jupyter (from aif360[all])\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting sphinx-rtd-theme (from aif360[all])\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting igraph[plotting] (from aif360[all])\n",
            "  Downloading igraph-0.11.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting lime (from aif360[all])\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (4.67.1)\n",
            "Collecting fairlearn~=0.7 (from aif360[all])\n",
            "  Downloading fairlearn-0.12.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting colorama (from aif360[all])\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: tensorflow>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (2.18.0)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (8.2.3)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (0.23.4)\n",
            "Collecting inFairness>=0.2.2 (from aif360[all])\n",
            "  Downloading inFairness-0.2.3-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting pytest-cov>=2.8.1 (from aif360[all])\n",
            "  Downloading pytest_cov-6.1.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting ipympl (from aif360[all])\n",
            "  Downloading ipympl-0.9.7-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (2.6.0+cu124)\n",
            "Requirement already satisfied: jinja2>3.1.0 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (3.1.6)\n",
            "Collecting adversarial-robustness-toolbox>=1.0.0 (from aif360[all])\n",
            "  Downloading adversarial_robustness_toolbox-1.19.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting BlackBoxAuditing (from aif360[all])\n",
            "  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (0.13.2)\n",
            "Requirement already satisfied: rpy2 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (3.5.17)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (4.5.0)\n",
            "Requirement already satisfied: pytest>=3.5 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (8.3.5)\n",
            "Collecting pot (from aif360[all])\n",
            "  Downloading POT-0.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Requirement already satisfied: cvxpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from aif360[all]) (1.6.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360[all]) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360[all]) (75.2.0)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.0->aif360[all]) (1.0.3)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.0->aif360[all]) (0.10.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.0->aif360[all]) (3.2.7.post2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>3.1.0->aif360[all]) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->aif360[all]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->aif360[all]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->aif360[all]) (2025.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=3.5->aif360[all]) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest>=3.5->aif360[all]) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=3.5->aif360[all]) (1.5.0)\n",
            "Collecting coverage>=7.5 (from coverage[toml]>=7.5->pytest-cov>=2.8.1->aif360[all])\n",
            "  Downloading coverage-7.8.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->aif360[all]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->aif360[all]) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (2.32.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->aif360[all])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->aif360[all])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->aif360[all])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->aif360[all])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->aif360[all])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->aif360[all])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->aif360[all])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->aif360[all])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->aif360[all])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->aif360[all])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->aif360[all]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->aif360[all]) (1.3.0)\n",
            "Collecting texttable>=1.6.2 (from igraph[plotting]; extra == \"all\"->aif360[all])\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting cairocffi>=1.2.0 (from igraph[plotting]; extra == \"all\"->aif360[all])\n",
            "  Downloading cairocffi-1.7.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: ipython<10 in /usr/local/lib/python3.11/dist-packages (from ipympl->aif360[all]) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.11/dist-packages (from ipympl->aif360[all]) (7.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from ipympl->aif360[all]) (11.2.1)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.11/dist-packages (from ipympl->aif360[all]) (5.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360[all]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360[all]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360[all]) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360[all]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->aif360[all]) (3.2.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter->aif360[all]) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter->aif360[all]) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter->aif360[all]) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter->aif360[all]) (6.17.1)\n",
            "Collecting jupyterlab (from jupyter->aif360[all])\n",
            "  Downloading jupyterlab-4.4.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime->aif360[all]) (0.25.2)\n",
            "Requirement already satisfied: cffi>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from rpy2->aif360[all]) (1.17.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from rpy2->aif360[all]) (5.3.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch->aif360[all]) (0.9.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.0.0)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.19.1)\n",
            "Requirement already satisfied: docutils<0.22,>=0.20 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (0.21.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx->aif360[all]) (3.1.0)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->aif360[all])\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.13.1->aif360[all]) (0.45.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.15.1->rpy2->aif360[all]) (2.22)\n",
            "Collecting jedi>=0.16 (from ipython<10->ipympl->aif360[all])\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->aif360[all]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->aif360[all]) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->aif360[all]) (3.0.51)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->aif360[all]) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl->aif360[all]) (4.9.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (3.0.14)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->aif360[all]) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->aif360[all]) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->aif360[all]) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->aif360[all]) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->aif360[all]) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter->aif360[all]) (6.4.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=1.13.1->aif360[all]) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=1.13.1->aif360[all]) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=1.13.1->aif360[all]) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=1.13.1->aif360[all]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=1.13.1->aif360[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=1.13.1->aif360[all]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=1.13.1->aif360[all]) (2025.1.31)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime->aif360[all]) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime->aif360[all]) (2025.3.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime->aif360[all]) (0.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.13.1->aif360[all]) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.13.1->aif360[all]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.13.1->aif360[all]) (3.1.3)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter->aif360[all])\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->aif360[all]) (0.28.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->aif360[all]) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter->aif360[all])\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter->aif360[all])\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter->aif360[all])\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter->aif360[all]) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->aif360[all]) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter->aif360[all]) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->aif360[all]) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->aif360[all]) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->aif360[all]) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->aif360[all]) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter->aif360[all]) (1.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->aif360[all]) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->aif360[all]) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->aif360[all]) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->aif360[all]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter->aif360[all]) (0.16.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython<10->ipympl->aif360[all]) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->jupyter->aif360[all]) (4.3.7)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel->jupyter->aif360[all])\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all]) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter->aif360[all]) (21.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->aif360[all]) (0.4)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->aif360[all]) (4.23.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter->aif360[all]) (2.21.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython<10->ipympl->aif360[all]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<10->ipympl->aif360[all]) (0.2.13)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter->aif360[all]) (2.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=1.13.1->aif360[all]) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter->aif360[all]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->aif360[all]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->aif360[all]) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->aif360[all]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->aif360[all]) (0.24.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all]) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=1.13.1->aif360[all]) (0.1.2)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all]) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all]) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->aif360[all])\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading adversarial_robustness_toolbox-1.19.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fairlearn-0.12.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inFairness-0.2.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading POT-0.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_cov-6.1.1-py3-none-any.whl (23 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aif360-0.6.1-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.7/259.7 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading ipympl-0.9.7-py3-none-any.whl (515 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.7/515.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading skorch-1.1.0-py3-none-any.whl (228 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cairocffi-1.7.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coverage-7.8.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.0/244.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading igraph-0.11.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.4.1-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m130.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: BlackBoxAuditing, lime\n",
            "  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394756 sha256=95d02b13103f94326aa538a76f199da42538c0d56a586ddd3f9754667b7cb34b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/8c/03/073e80e604151fb4cdc68b2e56a97f338d7723e4a4ab5e3823\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=48be41d775663309cab70bac529824fff4a5e2e3667ec66977468821ef3560f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built BlackBoxAuditing lime\n",
            "Installing collected packages: texttable, uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, json5, jedi, igraph, fqdn, coverage, colorama, async-lru, pot, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jupyter-server-terminals, jupyter-client, cairocffi, arrow, sphinxcontrib-jquery, skorch, pytest-cov, nvidia-cusolver-cu12, lime, isoduration, fairlearn, BlackBoxAuditing, aif360, adversarial-robustness-toolbox, sphinx-rtd-theme, jupyter-events, inFairness, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter, ipympl\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "Successfully installed BlackBoxAuditing-0.1.54 adversarial-robustness-toolbox-1.19.1 aif360-0.6.1 arrow-1.3.0 async-lru-2.0.5 cairocffi-1.7.1 colorama-0.4.6 coverage-7.8.0 fairlearn-0.12.0 fqdn-1.5.1 igraph-0.11.8 inFairness-0.2.3 ipympl-0.9.7 isoduration-20.11.0 jedi-0.19.2 json5-0.12.0 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.1 jupyterlab-server-2.27.3 lime-0.2.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 overrides-7.7.0 pot-0.9.5 pytest-cov-6.1.1 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 skorch-1.1.0 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1 texttable-1.7.0 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "665f4228-61c8-45f0-beb2-7e9f4481aea0",
      "metadata": {
        "id": "665f4228-61c8-45f0-beb2-7e9f4481aea0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "10d46c05-0e00-4c81-84e4-850a9f512abe",
      "metadata": {
        "id": "10d46c05-0e00-4c81-84e4-850a9f512abe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YSVPD9OWinvt"
      },
      "id": "YSVPD9OWinvt",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bafbfd6f-0210-4a9d-94fc-021ed0ee8649",
      "metadata": {
        "id": "bafbfd6f-0210-4a9d-94fc-021ed0ee8649"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a3e42370-c8a8-489d-bae3-d9db4ad2add1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3e42370-c8a8-489d-bae3-d9db4ad2add1",
        "outputId": "347811a5-3931-4ff8-8965-93a508823e3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
            "  vect_normalized_discounted_cumulative_gain = vmap(\n",
            "/usr/local/lib/python3.11/dist-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
            "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
          ]
        }
      ],
      "source": [
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import ClassificationMetric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d1100037-6aee-4d18-badb-7d75b54dba27",
      "metadata": {
        "id": "d1100037-6aee-4d18-badb-7d75b54dba27"
      },
      "outputs": [],
      "source": [
        "from aif360.algorithms.preprocessing import (\n",
        "    Reweighing,\n",
        "    DisparateImpactRemover,\n",
        "    LFR\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9befe73e-17ea-4afb-bfb2-a78322627677",
      "metadata": {
        "id": "9befe73e-17ea-4afb-bfb2-a78322627677"
      },
      "outputs": [],
      "source": [
        "from aif360.algorithms.inprocessing import (\n",
        "    MetaFairClassifier,\n",
        "    GerryFairClassifier,\n",
        "    PrejudiceRemover,\n",
        "    ExponentiatedGradientReduction,\n",
        "    GridSearchReduction,\n",
        "    ARTClassifier,\n",
        "    AdversarialDebiasing\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "93adf662-a1c5-4844-8695-5a82d5c94534",
      "metadata": {
        "id": "93adf662-a1c5-4844-8695-5a82d5c94534"
      },
      "outputs": [],
      "source": [
        "from aif360.algorithms.postprocessing import (\n",
        "    RejectOptionClassification,\n",
        "    CalibratedEqOddsPostprocessing,\n",
        "    EqOddsPostprocessing\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f17eadf7-3bd8-4371-879f-3234cf8e1f56",
      "metadata": {
        "id": "f17eadf7-3bd8-4371-879f-3234cf8e1f56"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path='/content/gmsc-training.csv'"
      ],
      "metadata": {
        "id": "3_gw217oir9O"
      },
      "id": "3_gw217oir9O",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f6311641-4754-4ad3-850a-e14b67df2a63",
      "metadata": {
        "id": "f6311641-4754-4ad3-850a-e14b67df2a63"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_gmsc_csv(csv_path):\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    # Load the GMSC dataset\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Drop the unnecessary index column\n",
        "    df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "    # Fill missing values\n",
        "    df['MonthlyIncome'] = df['MonthlyIncome'].fillna(df['MonthlyIncome'].median())\n",
        "    df['NumberOfDependents'] = df['NumberOfDependents'].fillna(df['NumberOfDependents'].median())\n",
        "\n",
        "    # Flip labels: 0 → 1 (Good), 1 → 0 (Bad)\n",
        "    df['target'] = df['SeriousDlqin2yrs'].apply(lambda x: 1 if x == 1 else 0)\n",
        "    df.drop(columns=['SeriousDlqin2yrs'], inplace=True)\n",
        "\n",
        "    # Protected attribute: age >= 25 → privileged\n",
        "    df['age_binary'] = df['age'].apply(lambda x: 1 if x >= 25 else 0)\n",
        "\n",
        "    # Features\n",
        "    df_features = df.drop(columns=['target', 'age', 'age_binary'])\n",
        "\n",
        "    # Feature matrix (X), Labels (y), and Protected Attribute (protected)\n",
        "    X = df_features\n",
        "    y = df['target']\n",
        "    protected = df['age_binary']\n",
        "\n",
        "    # Standardize numeric features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test, prot_train, prot_test = train_test_split(\n",
        "        X_scaled, y, protected, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, prot_train, prot_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "461c1d97-01b0-4abe-9bcb-6eb8dcd1f905",
      "metadata": {
        "id": "461c1d97-01b0-4abe-9bcb-6eb8dcd1f905"
      },
      "outputs": [],
      "source": [
        "def load_gmsc_data(csv_path):\n",
        "    import pandas as pd\n",
        "\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Drop unnecessary index column\n",
        "    df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "    # Fill missing values\n",
        "    df['MonthlyIncome'] = df['MonthlyIncome'].fillna(df['MonthlyIncome'].median())\n",
        "    df['NumberOfDependents'] = df['NumberOfDependents'].fillna(df['NumberOfDependents'].median())\n",
        "\n",
        "    # Flip labels: 0 → 1 (Good), 1 → 0 (Bad)\n",
        "    df['target'] = df['SeriousDlqin2yrs'].apply(lambda x: 1 if x == 1 else 0)\n",
        "    df.drop(columns=['SeriousDlqin2yrs'], inplace=True)\n",
        "\n",
        "    # Protected attribute: age >= 25 is privileged\n",
        "    df['age_binary'] = df['age'].apply(lambda x: 1 if x >= 25 else 0)\n",
        "\n",
        "    # Raw features (excluding target and protected columns)\n",
        "    X_raw = df.drop(columns=['target', 'age', 'age_binary'])\n",
        "    y = df['target'].values\n",
        "    prot = df['age_binary'].values\n",
        "\n",
        "    return X_raw, y, prot\n",
        "\n",
        "def preprocess_data(X_raw, y, prot):\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    import numpy as np\n",
        "\n",
        "    # GMSC dataset: only numeric columns\n",
        "    num_cols = X_raw.columns.tolist()\n",
        "\n",
        "    # Train-test split\n",
        "    X_raw_train, X_raw_test, y_train, y_test, prot_train, prot_test = train_test_split(\n",
        "        X_raw, y, prot, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # No encoding needed (no categorical features)\n",
        "    X_train_num = X_raw_train[num_cols].values\n",
        "    X_test_num = X_raw_test[num_cols].values\n",
        "\n",
        "    # Normalize\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train_num)\n",
        "    X_test = scaler.transform(X_test_num)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, prot_train, prot_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "16e9680e-c1f3-4356-87cc-a3b83106b714",
      "metadata": {
        "id": "16e9680e-c1f3-4356-87cc-a3b83106b714"
      },
      "outputs": [],
      "source": [
        "def load_gmsc_data_inprocess(csv_path):\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Drop unnecessary index column\n",
        "    df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "    # Fill missing values\n",
        "    df['MonthlyIncome'] = df['MonthlyIncome'].fillna(df['MonthlyIncome'].median())\n",
        "    df['NumberOfDependents'] = df['NumberOfDependents'].fillna(df['NumberOfDependents'].median())\n",
        "\n",
        "    # Flip labels: 0 → 1 (Good), 1 → 0 (Bad)\n",
        "    df['target'] = df['SeriousDlqin2yrs'].apply(lambda x: 1 if x == 1 else 0)\n",
        "    df.drop(columns=['SeriousDlqin2yrs'], inplace=True)\n",
        "\n",
        "    # Protected attribute: age >= 25 is privileged\n",
        "    df['age_binary'] = df['age'].apply(lambda x: 1 if x >= 25 else 0)\n",
        "\n",
        "    # Features (drop target, age, and protected attribute)\n",
        "    X_raw = df.drop(columns=['target', 'age', 'age_binary'])\n",
        "    y = df['target'].values\n",
        "    prot = df['age_binary'].values\n",
        "\n",
        "    # Train-test split\n",
        "    X_train_raw, X_test_raw, y_train, y_test, prot_train, prot_test = train_test_split(\n",
        "        X_raw, y, prot, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # GMSC dataset: all columns are numeric\n",
        "    X_train_num = X_train_raw.values\n",
        "    X_test_num = X_test_raw.values\n",
        "\n",
        "    # Standardize all features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train_num)\n",
        "    X_test = scaler.transform(X_test_num)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, prot_train, prot_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "070d3f48-baca-4830-9d0f-1fcb4ecb716c",
      "metadata": {
        "id": "070d3f48-baca-4830-9d0f-1fcb4ecb716c"
      },
      "outputs": [],
      "source": [
        "def train_baseline_model(X_train, y_train, sample_weight=None):\n",
        "    model = XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weight)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6f97857f-9f14-41e0-8b36-3d555a21f092",
      "metadata": {
        "id": "6f97857f-9f14-41e0-8b36-3d555a21f092"
      },
      "outputs": [],
      "source": [
        "def evaluate_fairness(y_true, y_pred, prot, X=None):\n",
        "    df = pd.DataFrame(np.hstack((X, y_true[:, None], prot[:, None])),\n",
        "                      columns=[f\"x{i}\" for i in range(X.shape[1])] + ['label', 'protected'])\n",
        "\n",
        "    dataset_true = BinaryLabelDataset(df=df,\n",
        "                                      label_names=[\"label\"],\n",
        "                                      protected_attribute_names=[\"protected\"],\n",
        "                                      favorable_label=0, unfavorable_label=1)\n",
        "\n",
        "    pred_dataset = dataset_true.copy()\n",
        "    pred_dataset.labels = y_pred.reshape(-1, 1)\n",
        "\n",
        "    metric = ClassificationMetric(dataset_true, pred_dataset,\n",
        "                                  privileged_groups=[{'protected': 1}],\n",
        "                                  unprivileged_groups=[{'protected': 0}])\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'disparate_impact': metric.disparate_impact(),\n",
        "        'statistical_parity_difference': metric.statistical_parity_difference(),\n",
        "        'equal_opportunity_difference': metric.equal_opportunity_difference()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e3e34149-f3e6-4e8e-8a67-8553d90ce49f",
      "metadata": {
        "id": "e3e34149-f3e6-4e8e-8a67-8553d90ce49f"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_test, y_test, prot_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    return evaluate_fairness(y_test, y_pred, prot_test, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dd1e5826-f18c-4e66-b805-86f97430ae2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd1e5826-f18c-4e66-b805-86f97430ae2e",
        "outputId": "958ca3f7-3e10-4309-cec7-6c721d1a6ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:30:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9348,\n",
              " 'disparate_impact': np.float64(0.9916306609265991),\n",
              " 'statistical_parity_difference': np.float64(-0.008171566961345467),\n",
              " 'equal_opportunity_difference': np.float64(-0.006311552664603592)}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#XGboost\n",
        "X_train, X_test, y_train, y_test, prot_train, prot_test = load_and_preprocess_gmsc_csv(csv_path)\n",
        "baseline_model = train_baseline_model(X_train, y_train)\n",
        "baseline_metrics = evaluate_model(baseline_model, X_test, y_test.to_numpy(), prot_test.to_numpy())\n",
        "\n",
        "baseline_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2f84a9b3-fd1e-4ce5-ae04-4abb49b470fe",
      "metadata": {
        "id": "2f84a9b3-fd1e-4ce5-ae04-4abb49b470fe"
      },
      "outputs": [],
      "source": [
        "##disparate impact\n",
        "def apply_disparate_impact_remover(X_train, y_train, prot_train, repair_level=1.0):\n",
        "    df = pd.DataFrame(X_train)\n",
        "    df['target'] = y_train.values if hasattr(y_train, 'values') else y_train\n",
        "    df['protected'] = prot_train.values if hasattr(prot_train, 'values') else prot_train\n",
        "\n",
        "    dataset = BinaryLabelDataset(\n",
        "        favorable_label=0,  # <-- GOOD outcome = 0 for GMSC\n",
        "        unfavorable_label=1,\n",
        "        df=df,\n",
        "        label_names=['target'],\n",
        "        protected_attribute_names=['protected']\n",
        "    )\n",
        "\n",
        "    dir_remover = DisparateImpactRemover(repair_level=repair_level)\n",
        "    repaired_dataset = dir_remover.fit_transform(dataset)\n",
        "\n",
        "    X_repaired = pd.DataFrame(repaired_dataset.features)\n",
        "    y_repaired = pd.Series(repaired_dataset.labels.ravel())\n",
        "    prot_repaired = pd.Series(repaired_dataset.protected_attributes.ravel())\n",
        "\n",
        "    return X_repaired, y_repaired, prot_repaired"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c8c5e310-07bf-4065-85ec-c10e0c0959e1",
      "metadata": {
        "id": "c8c5e310-07bf-4065-85ec-c10e0c0959e1"
      },
      "outputs": [],
      "source": [
        "inprocess_results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7acbe9b5-1a0d-4688-b93f-66e432de9278",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7acbe9b5-1a0d-4688-b93f-66e432de9278",
        "outputId": "19a174f1-d63c-4ca4-9b93-66c295f27a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:30:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9344761904761905,\n",
              " 'disparate_impact': np.float64(0.9733450407231932),\n",
              " 'statistical_parity_difference': np.float64(-0.026210380956125934),\n",
              " 'equal_opportunity_difference': np.float64(-0.019605082167584387)}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Apply DIR ONLY to training data\n",
        "X_train_repaired, y_train_repaired, prot_train_repaired = apply_disparate_impact_remover(\n",
        "    pd.DataFrame(X_train), y_train, prot_train\n",
        ")\n",
        "\n",
        "# Split repaired training data into sub-train and validation\n",
        "X_subtrain, X_val, y_subtrain, y_val, prot_subtrain, prot_val = train_test_split(\n",
        "    X_train_repaired, y_train_repaired, prot_train_repaired, test_size=0.3, random_state=42, stratify=y_train_repaired\n",
        ")\n",
        "\n",
        "# Train model on sub-train\n",
        "fair_model = train_baseline_model(X_subtrain, y_subtrain)\n",
        "\n",
        "# Evaluate model on repaired validation\n",
        "fair_metrics = evaluate_model(\n",
        "    fair_model,\n",
        "    X_val.to_numpy(),\n",
        "    y_val.to_numpy(),\n",
        "    prot_val.to_numpy()\n",
        ")\n",
        "inprocess_results['Disparate_Impact_Remover'] = fair_metrics\n",
        "fair_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "133f3630-166e-434d-ace8-9eb408ee8341",
      "metadata": {
        "id": "133f3630-166e-434d-ace8-9eb408ee8341"
      },
      "outputs": [],
      "source": [
        "##LFR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c448071f-a53e-4c0b-bee6-92582c5b5873",
      "metadata": {
        "id": "c448071f-a53e-4c0b-bee6-92582c5b5873"
      },
      "outputs": [],
      "source": [
        "def apply_lfr(X_train, y_train, prot_train):\n",
        "    df = pd.DataFrame(X_train)\n",
        "    df['target'] = y_train.values\n",
        "    df['protected'] = prot_train.values\n",
        "\n",
        "    dataset = BinaryLabelDataset(\n",
        "        favorable_label=0,\n",
        "        unfavorable_label=1,\n",
        "        df=df,\n",
        "        label_names=['target'],\n",
        "        protected_attribute_names=['protected']\n",
        "    )\n",
        "\n",
        "    lfr = LFR(unprivileged_groups=[{'protected': 0}],\n",
        "          privileged_groups=[{'protected': 1}],\n",
        "          k=10, Ax=0.01, Ay=1.0, Az=0.1, verbose=0)\n",
        "\n",
        "    lfr.fit(dataset)\n",
        "    transformed_dataset = lfr.transform(dataset)\n",
        "\n",
        "    X_transformed = pd.DataFrame(transformed_dataset.features)\n",
        "    y_transformed = pd.Series(transformed_dataset.labels.ravel())\n",
        "    prot_transformed = pd.Series(transformed_dataset.protected_attributes.ravel())\n",
        "\n",
        "    return X_transformed, y_transformed, prot_transformed, lfr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "939b219c-422f-4925-9010-7f945614723b",
      "metadata": {
        "id": "939b219c-422f-4925-9010-7f945614723b"
      },
      "outputs": [],
      "source": [
        "X_train_lfr, y_train_lfr, prot_train_lfr, lfr_model = apply_lfr(pd.DataFrame(X_train), y_train, prot_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "11004253-b8a2-4763-9f7c-44edf518793d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11004253-b8a2-4763-9f7c-44edf518793d",
        "outputId": "94f5a040-eade-41ad-c5ab-db9c5e97def7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in y_train_lfr: [0. 1.]\n"
          ]
        }
      ],
      "source": [
        "print(\"Unique labels in y_train_lfr:\", np.unique(y_train_lfr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "0ae50d92-d376-4a57-8159-7e3bd3e3b9b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ae50d92-d376-4a57-8159-7e3bd3e3b9b6",
        "outputId": "ae593be8-6725-4f52-bf38-ebe4991abf7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:38:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "fair_lfr_model = train_baseline_model(X_train_lfr, y_train_lfr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "84d6c5a0-ca61-4443-9719-96fcf29dde78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84d6c5a0-ca61-4443-9719-96fcf29dde78",
        "outputId": "24a2559a-d528-48fc-da5d-b19098f6a28a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9999555555555556,\n",
              " 'disparate_impact': np.float64(0.9572306676095039),\n",
              " 'statistical_parity_difference': np.float64(-0.04270676753913494),\n",
              " 'equal_opportunity_difference': np.float64(0.0)}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Apply LFR transformation on test set\n",
        "df_test = pd.DataFrame(X_test)\n",
        "df_test['target'] = y_test.values\n",
        "df_test['protected'] = prot_test.values\n",
        "\n",
        "test_dataset = BinaryLabelDataset(\n",
        "    favorable_label=0,\n",
        "    unfavorable_label=1,\n",
        "    df=df_test,\n",
        "    label_names=['target'],\n",
        "    protected_attribute_names=['protected']\n",
        ")\n",
        "\n",
        "transformed_test_dataset = lfr_model.transform(test_dataset)\n",
        "\n",
        "X_test_lfr = pd.DataFrame(transformed_test_dataset.features)\n",
        "y_test_lfr = pd.Series(transformed_test_dataset.labels.ravel())\n",
        "prot_test_lfr = pd.Series(transformed_test_dataset.protected_attributes.ravel())\n",
        "\n",
        "# Evaluate\n",
        "fair_lfr_metrics = evaluate_model(\n",
        "    fair_lfr_model,\n",
        "    X_test_lfr.to_numpy(),\n",
        "    y_test_lfr.to_numpy(),\n",
        "    prot_test_lfr.to_numpy()\n",
        ")\n",
        "inprocess_results['LFR']=fair_lfr_metrics\n",
        "\n",
        "fair_lfr_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "6dc25394-3463-4068-a77e-527e418e2380",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dc25394-3463-4068-a77e-527e418e2380",
        "outputId": "78b16182-12f7-49d3-d46c-24c9c75de1cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0., 1.]), array([44908,    92]))\n"
          ]
        }
      ],
      "source": [
        "print(np.unique(y_test_lfr, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "c54bdfef-1220-4141-9a75-12958512ce74",
      "metadata": {
        "id": "c54bdfef-1220-4141-9a75-12958512ce74"
      },
      "outputs": [],
      "source": [
        "#reweighing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b258ded4-8982-4d0f-8fdc-9a61dee16486",
      "metadata": {
        "id": "b258ded4-8982-4d0f-8fdc-9a61dee16486"
      },
      "outputs": [],
      "source": [
        "def apply_reweighing(X_train, y_train, prot_train):\n",
        "    df_train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1), prot_train.reshape(-1, 1))),\n",
        "                            columns=[f\"x{i}\" for i in range(X_train.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_train = BinaryLabelDataset(\n",
        "        favorable_label=0,\n",
        "        unfavorable_label=1,\n",
        "        df=df_train,\n",
        "        label_names=[\"label\"],\n",
        "        protected_attribute_names=[\"protected\"]\n",
        "    )\n",
        "    RW = Reweighing(unprivileged_groups=[{'protected': 0}], privileged_groups=[{'protected': 1}])\n",
        "    bld_rw = RW.fit_transform(bld_train)\n",
        "\n",
        "    return bld_rw.features, bld_rw.labels.ravel(), bld_rw.instance_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f3d911c3-21e4-4878-9329-bf49418e65bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3d911c3-21e4-4878-9329-bf49418e65bc",
        "outputId": "2f968d2f-4ad9-486a-f65c-91ff0a7b49fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:38:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9345333333333333,\n",
              " 'disparate_impact': np.float64(1.0024113023945682),\n",
              " 'statistical_parity_difference': np.float64(0.0023502519558527),\n",
              " 'equal_opportunity_difference': np.float64(-0.0012591940035652227)}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test, prot_train, prot_test = preprocess_data(*load_gmsc_data(csv_path))\n",
        "\n",
        "X_rw, y_rw, sample_weights = apply_reweighing(X_train, y_train, prot_train)\n",
        "\n",
        "expected_num_features = X_rw.shape[1]\n",
        "\n",
        "if X_test.shape[1] < expected_num_features:\n",
        "    padding = expected_num_features - X_test.shape[1]\n",
        "    X_test_aligned = np.hstack((X_test, np.zeros((X_test.shape[0], padding))))\n",
        "elif X_test.shape[1] > expected_num_features:\n",
        "    X_test_aligned = X_test[:, :expected_num_features]\n",
        "else:\n",
        "    X_test_aligned = X_test\n",
        "\n",
        "model_rw = train_baseline_model(X_rw, y_rw, sample_weight=sample_weights)\n",
        "\n",
        "reweighing_metric = evaluate_model(model_rw, X_test_aligned, y_test, prot_test)\n",
        "\n",
        "inprocess_results['reweighing'] = reweighing_metric\n",
        "reweighing_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3570eed6-54a6-4b37-afb7-544e092afe4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3570eed6-54a6-4b37-afb7-544e092afe4c",
        "outputId": "3d7aeef2-ed30-4c79-bd8f-c9bcfcdee71d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Disparate_Impact_Remover\n",
            "  accuracy: 0.9345\n",
            "  disparate_impact: 0.9733\n",
            "  statistical_parity_difference: -0.0262\n",
            "  equal_opportunity_difference: -0.0196\n",
            "\n",
            "🔹 LFR\n",
            "  accuracy: 1.0000\n",
            "  disparate_impact: 0.9572\n",
            "  statistical_parity_difference: -0.0427\n",
            "  equal_opportunity_difference: 0.0000\n",
            "\n",
            "🔹 reweighing\n",
            "  accuracy: 0.9345\n",
            "  disparate_impact: 1.0024\n",
            "  statistical_parity_difference: 0.0024\n",
            "  equal_opportunity_difference: -0.0013\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for model, metrics in inprocess_results.items():\n",
        "    print(f\"🔹 {model}\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "e86aee4e-04ca-478a-b6e4-3d21d22ea555",
      "metadata": {
        "id": "e86aee4e-04ca-478a-b6e4-3d21d22ea555"
      },
      "outputs": [],
      "source": [
        "#Inprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "69786608-b4de-408a-8e19-5d4c9502e0fe",
      "metadata": {
        "id": "69786608-b4de-408a-8e19-5d4c9502e0fe"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, prot_train, prot_test = load_gmsc_data_inprocess(csv_path)\n",
        "results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "583ba3c8-b431-498a-8be2-b1bdf7383a42",
      "metadata": {
        "id": "583ba3c8-b431-498a-8be2-b1bdf7383a42"
      },
      "outputs": [],
      "source": [
        "def train_gerryfair(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    df_train = pd.DataFrame(np.hstack((X_train, y_train[:, None], prot_train[:, None])),\n",
        "                            columns=[f\"x{i}\" for i in range(X_train.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_train = BinaryLabelDataset(df=df_train, label_names=[\"label\"], protected_attribute_names=[\"protected\"],\n",
        "                                   favorable_label=1, unfavorable_label=0)\n",
        "\n",
        "    df_test = pd.DataFrame(np.hstack((X_test, y_test[:, None], prot_test[:, None])),\n",
        "                           columns=[f\"x{i}\" for i in range(X_test.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_test = BinaryLabelDataset(df=df_test, label_names=[\"label\"], protected_attribute_names=[\"protected\"],\n",
        "                                  favorable_label=0, unfavorable_label=1)\n",
        "\n",
        "    clf = GerryFairClassifier(C=100, printflag=False, gamma=0.005, fairness_def='FP', max_iters=50)\n",
        "    clf.fit(bld_train)\n",
        "    pred = clf.predict(bld_test)\n",
        "\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "101f880f-199d-48e4-b350-27d3662020c1",
      "metadata": {
        "id": "101f880f-199d-48e4-b350-27d3662020c1"
      },
      "outputs": [],
      "source": [
        "results['GerryFair'] = train_gerryfair(X_train, y_train, prot_train, X_test, y_test, prot_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "922c7ba7-dedb-4c5d-8337-3b0bef8a2d05",
      "metadata": {
        "id": "922c7ba7-dedb-4c5d-8337-3b0bef8a2d05"
      },
      "outputs": [],
      "source": [
        "def train_prejudice_remover(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    df_train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1), prot_train.reshape(-1, 1))),\n",
        "                            columns=[f\"x{i}\" for i in range(X_train.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_train = BinaryLabelDataset(df=df_train,\n",
        "                                   label_names=[\"label\"],\n",
        "                                   protected_attribute_names=[\"protected\"],\n",
        "                                   favorable_label=0,\n",
        "                                   unfavorable_label=1)\n",
        "\n",
        "    df_test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1), prot_test.reshape(-1, 1))),\n",
        "                           columns=[f\"x{i}\" for i in range(X_test.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_test = BinaryLabelDataset(df=df_test,\n",
        "                                  label_names=[\"label\"],\n",
        "                                  protected_attribute_names=[\"protected\"],\n",
        "                                  favorable_label=0,\n",
        "                                  unfavorable_label=1)\n",
        "\n",
        "    clf = PrejudiceRemover(sensitive_attr=\"protected\", eta=25.0)\n",
        "    clf.fit(bld_train)\n",
        "    pred = clf.predict(bld_test)\n",
        "\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "854bd43e-b0c6-4c9f-984a-707befbb9289",
      "metadata": {
        "id": "854bd43e-b0c6-4c9f-984a-707befbb9289"
      },
      "outputs": [],
      "source": [
        "results['PrejudiceRemover'] = train_prejudice_remover(X_train, y_train, prot_train, X_test, y_test, prot_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "061c2dd4-8631-48db-877f-2b792fc0b22c",
      "metadata": {
        "id": "061c2dd4-8631-48db-877f-2b792fc0b22c"
      },
      "outputs": [],
      "source": [
        "def train_expgrad(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    df_train = pd.DataFrame(np.hstack((X_train, y_train[:, None], prot_train[:, None])),\n",
        "                            columns=[f\"x{i}\" for i in range(X_train.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_train = BinaryLabelDataset(df=df_train,\n",
        "                                   label_names=[\"label\"],\n",
        "                                   protected_attribute_names=[\"protected\"],\n",
        "                                   favorable_label=0,\n",
        "                                   unfavorable_label=1)\n",
        "\n",
        "    df_test = pd.DataFrame(np.hstack((X_test, y_test[:, None], prot_test[:, None])),\n",
        "                           columns=[f\"x{i}\" for i in range(X_test.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_test = BinaryLabelDataset(df=df_test,\n",
        "                                  label_names=[\"label\"],\n",
        "                                  protected_attribute_names=[\"protected\"],\n",
        "                                  favorable_label=0,\n",
        "                                  unfavorable_label=1)\n",
        "\n",
        "    expgrad = ExponentiatedGradientReduction(\n",
        "        estimator=LogisticRegression(solver='liblinear'),\n",
        "        constraints=\"DemographicParity\"\n",
        "    )\n",
        "    expgrad.fit(bld_train)\n",
        "\n",
        "    pred = expgrad.predict(bld_test)\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "a103effb-d435-4df2-a932-b9f1f3dbb5b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a103effb-d435-4df2-a932-b9f1f3dbb5b6",
        "outputId": "89afb98c-9c8b-44aa-af2d-3316e8d706f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "results['ExponentiatedGradient'] = train_expgrad(X_train, y_train, prot_train, X_test, y_test, prot_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "f766e6d8-5d07-47a2-9a50-14e44a44d857",
      "metadata": {
        "id": "f766e6d8-5d07-47a2-9a50-14e44a44d857"
      },
      "outputs": [],
      "source": [
        "def train_gridsearch(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    df_train = pd.DataFrame(np.hstack((X_train, y_train[:, None], prot_train[:, None])),\n",
        "                            columns=[f\"x{i}\" for i in range(X_train.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_train = BinaryLabelDataset(df=df_train,\n",
        "                                   label_names=[\"label\"],\n",
        "                                   protected_attribute_names=[\"protected\"],\n",
        "                                   favorable_label=0,\n",
        "                                   unfavorable_label=1)\n",
        "\n",
        "    df_test = pd.DataFrame(np.hstack((X_test, y_test[:, None], prot_test[:, None])),\n",
        "                           columns=[f\"x{i}\" for i in range(X_test.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_test = BinaryLabelDataset(df=df_test,\n",
        "                                  label_names=[\"label\"],\n",
        "                                  protected_attribute_names=[\"protected\"],\n",
        "                                  favorable_label=0,\n",
        "                                  unfavorable_label=1)\n",
        "\n",
        "    grid = GridSearchReduction(\n",
        "        estimator=LogisticRegression(solver='liblinear'),\n",
        "        constraints=\"DemographicParity\"\n",
        "    )\n",
        "    grid.fit(bld_train)\n",
        "\n",
        "    pred = grid.predict(bld_test)\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "3ae95dac-6c4c-41ee-9bf2-6e0d8468ffcb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ae95dac-6c4c-41ee-9bf2-6e0d8468ffcb",
        "outputId": "d802621d-452f-41ee-cbf4-684327a82eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "results['GridSearch'] = train_gridsearch(X_train, y_train, prot_train, X_test, y_test, prot_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "7cebb81e-2672-4318-a1d7-d5c4caed734d",
      "metadata": {
        "id": "7cebb81e-2672-4318-a1d7-d5c4caed734d"
      },
      "outputs": [],
      "source": [
        "tf.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "3431a154-7a4f-4f9d-8d7a-26b4aced0d9b",
      "metadata": {
        "id": "3431a154-7a4f-4f9d-8d7a-26b4aced0d9b"
      },
      "outputs": [],
      "source": [
        "def train_adversarial_debiasing(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    # Train data\n",
        "    tf.reset_default_graph()\n",
        "    df_train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1), prot_train.reshape(-1, 1))),\n",
        "                            columns=[f\"x{i}\" for i in range(X_train.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_train = BinaryLabelDataset(df=df_train,\n",
        "                                   label_names=[\"label\"],\n",
        "                                   protected_attribute_names=[\"protected\"],\n",
        "                                   favorable_label=0,\n",
        "                                   unfavorable_label=1)\n",
        "\n",
        "    # Test data\n",
        "    df_test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1), prot_test.reshape(-1, 1))),\n",
        "                           columns=[f\"x{i}\" for i in range(X_test.shape[1])] + [\"label\", \"protected\"])\n",
        "    bld_test = BinaryLabelDataset(df=df_test,\n",
        "                                  label_names=[\"label\"],\n",
        "                                  protected_attribute_names=[\"protected\"],\n",
        "                                  favorable_label=0,\n",
        "                                  unfavorable_label=1)\n",
        "\n",
        "    # TensorFlow session\n",
        "    sess = tf.Session()\n",
        "\n",
        "    clf = AdversarialDebiasing(\n",
        "        privileged_groups=[{'protected': 1}],\n",
        "        unprivileged_groups=[{'protected': 0}],\n",
        "        scope_name='adv_debiasing',\n",
        "        sess=sess,\n",
        "        num_epochs=50,\n",
        "        batch_size=64,\n",
        "        debias=True\n",
        "    )\n",
        "\n",
        "    clf.fit(bld_train)\n",
        "    pred = clf.predict(bld_test)\n",
        "\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "21d5a66b-2a11-49c4-b20e-8314760fe345",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21d5a66b-2a11-49c4-b20e-8314760fe345",
        "outputId": "103a4322-5d77-46bb-b1ea-064166b9bbe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 0.599937; batch adversarial loss: 0.778756\n",
            "epoch 0; iter: 200; batch classifier loss: 0.195469; batch adversarial loss: 0.544826\n",
            "epoch 0; iter: 400; batch classifier loss: 0.361422; batch adversarial loss: 0.377997\n",
            "epoch 0; iter: 600; batch classifier loss: 0.090559; batch adversarial loss: 0.271091\n",
            "epoch 0; iter: 800; batch classifier loss: 0.273671; batch adversarial loss: 0.190935\n",
            "epoch 0; iter: 1000; batch classifier loss: 0.140055; batch adversarial loss: 0.145991\n",
            "epoch 0; iter: 1200; batch classifier loss: 0.267035; batch adversarial loss: 0.160065\n",
            "epoch 0; iter: 1400; batch classifier loss: 0.130808; batch adversarial loss: 0.142225\n",
            "epoch 0; iter: 1600; batch classifier loss: 0.176021; batch adversarial loss: 0.082687\n",
            "epoch 1; iter: 0; batch classifier loss: 0.259216; batch adversarial loss: 0.129331\n",
            "epoch 1; iter: 200; batch classifier loss: 0.164216; batch adversarial loss: 0.157572\n",
            "epoch 1; iter: 400; batch classifier loss: 0.202294; batch adversarial loss: 0.062651\n",
            "epoch 1; iter: 600; batch classifier loss: 0.220859; batch adversarial loss: 0.194285\n",
            "epoch 1; iter: 800; batch classifier loss: 0.260378; batch adversarial loss: 0.049142\n",
            "epoch 1; iter: 1000; batch classifier loss: 0.131627; batch adversarial loss: 0.037450\n",
            "epoch 1; iter: 1200; batch classifier loss: 0.343680; batch adversarial loss: 0.037768\n",
            "epoch 1; iter: 1400; batch classifier loss: 0.276703; batch adversarial loss: 0.087469\n",
            "epoch 1; iter: 1600; batch classifier loss: 0.171196; batch adversarial loss: 0.031740\n",
            "epoch 2; iter: 0; batch classifier loss: 0.180999; batch adversarial loss: 0.083926\n",
            "epoch 2; iter: 200; batch classifier loss: 0.276807; batch adversarial loss: 0.025937\n",
            "epoch 2; iter: 400; batch classifier loss: 0.221692; batch adversarial loss: 0.083063\n",
            "epoch 2; iter: 600; batch classifier loss: 0.268044; batch adversarial loss: 0.088220\n",
            "epoch 2; iter: 800; batch classifier loss: 0.097597; batch adversarial loss: 0.086527\n",
            "epoch 2; iter: 1000; batch classifier loss: 0.263577; batch adversarial loss: 0.147888\n",
            "epoch 2; iter: 1200; batch classifier loss: 0.101128; batch adversarial loss: 0.086983\n",
            "epoch 2; iter: 1400; batch classifier loss: 0.226513; batch adversarial loss: 0.017833\n",
            "epoch 2; iter: 1600; batch classifier loss: 0.182602; batch adversarial loss: 0.021468\n",
            "epoch 3; iter: 0; batch classifier loss: 0.151557; batch adversarial loss: 0.021503\n",
            "epoch 3; iter: 200; batch classifier loss: 0.183390; batch adversarial loss: 0.087396\n",
            "epoch 3; iter: 400; batch classifier loss: 0.196740; batch adversarial loss: 0.150025\n",
            "epoch 3; iter: 600; batch classifier loss: 0.159414; batch adversarial loss: 0.083092\n",
            "epoch 3; iter: 800; batch classifier loss: 0.168755; batch adversarial loss: 0.080500\n",
            "epoch 3; iter: 1000; batch classifier loss: 0.393847; batch adversarial loss: 0.016947\n",
            "epoch 3; iter: 1200; batch classifier loss: 0.271955; batch adversarial loss: 0.083281\n",
            "epoch 3; iter: 1400; batch classifier loss: 0.212843; batch adversarial loss: 0.084358\n",
            "epoch 3; iter: 1600; batch classifier loss: 0.077404; batch adversarial loss: 0.014198\n",
            "epoch 4; iter: 0; batch classifier loss: 0.228338; batch adversarial loss: 0.014747\n",
            "epoch 4; iter: 200; batch classifier loss: 0.214338; batch adversarial loss: 0.088203\n",
            "epoch 4; iter: 400; batch classifier loss: 0.225651; batch adversarial loss: 0.084164\n",
            "epoch 4; iter: 600; batch classifier loss: 0.059246; batch adversarial loss: 0.083678\n",
            "epoch 4; iter: 800; batch classifier loss: 0.332131; batch adversarial loss: 0.182989\n",
            "epoch 4; iter: 1000; batch classifier loss: 0.337882; batch adversarial loss: 0.018878\n",
            "epoch 4; iter: 1200; batch classifier loss: 0.285469; batch adversarial loss: 0.016076\n",
            "epoch 4; iter: 1400; batch classifier loss: 0.161698; batch adversarial loss: 0.068349\n",
            "epoch 4; iter: 1600; batch classifier loss: 0.140758; batch adversarial loss: 0.012415\n",
            "epoch 5; iter: 0; batch classifier loss: 0.455965; batch adversarial loss: 0.144972\n",
            "epoch 5; iter: 200; batch classifier loss: 0.230316; batch adversarial loss: 0.152512\n",
            "epoch 5; iter: 400; batch classifier loss: 0.197197; batch adversarial loss: 0.019865\n",
            "epoch 5; iter: 600; batch classifier loss: 0.220897; batch adversarial loss: 0.156840\n",
            "epoch 5; iter: 800; batch classifier loss: 0.105385; batch adversarial loss: 0.015574\n",
            "epoch 5; iter: 1000; batch classifier loss: 0.082574; batch adversarial loss: 0.014627\n",
            "epoch 5; iter: 1200; batch classifier loss: 0.171537; batch adversarial loss: 0.227467\n",
            "epoch 5; iter: 1400; batch classifier loss: 0.238672; batch adversarial loss: 0.146046\n",
            "epoch 5; iter: 1600; batch classifier loss: 0.041606; batch adversarial loss: 0.012656\n",
            "epoch 6; iter: 0; batch classifier loss: 0.204034; batch adversarial loss: 0.015627\n",
            "epoch 6; iter: 200; batch classifier loss: 0.224294; batch adversarial loss: 0.015748\n",
            "epoch 6; iter: 400; batch classifier loss: 0.270426; batch adversarial loss: 0.086503\n",
            "epoch 6; iter: 600; batch classifier loss: 0.170976; batch adversarial loss: 0.087857\n",
            "epoch 6; iter: 800; batch classifier loss: 0.191983; batch adversarial loss: 0.014066\n",
            "epoch 6; iter: 1000; batch classifier loss: 0.053517; batch adversarial loss: 0.290550\n",
            "epoch 6; iter: 1200; batch classifier loss: 0.086150; batch adversarial loss: 0.082872\n",
            "epoch 6; iter: 1400; batch classifier loss: 0.168332; batch adversarial loss: 0.082483\n",
            "epoch 6; iter: 1600; batch classifier loss: 0.268847; batch adversarial loss: 0.017094\n",
            "epoch 7; iter: 0; batch classifier loss: 0.157904; batch adversarial loss: 0.219514\n",
            "epoch 7; iter: 200; batch classifier loss: 0.302028; batch adversarial loss: 0.013485\n",
            "epoch 7; iter: 400; batch classifier loss: 0.224450; batch adversarial loss: 0.015309\n",
            "epoch 7; iter: 600; batch classifier loss: 0.290359; batch adversarial loss: 0.015606\n",
            "epoch 7; iter: 800; batch classifier loss: 0.373521; batch adversarial loss: 0.013918\n",
            "epoch 7; iter: 1000; batch classifier loss: 0.196569; batch adversarial loss: 0.074018\n",
            "epoch 7; iter: 1200; batch classifier loss: 0.323959; batch adversarial loss: 0.083681\n",
            "epoch 7; iter: 1400; batch classifier loss: 0.285074; batch adversarial loss: 0.071982\n",
            "epoch 7; iter: 1600; batch classifier loss: 0.140477; batch adversarial loss: 0.016899\n",
            "epoch 8; iter: 0; batch classifier loss: 0.181772; batch adversarial loss: 0.150235\n",
            "epoch 8; iter: 200; batch classifier loss: 0.264642; batch adversarial loss: 0.151842\n",
            "epoch 8; iter: 400; batch classifier loss: 0.216158; batch adversarial loss: 0.153579\n",
            "epoch 8; iter: 600; batch classifier loss: 0.304524; batch adversarial loss: 0.080861\n",
            "epoch 8; iter: 800; batch classifier loss: 0.236836; batch adversarial loss: 0.080852\n",
            "epoch 8; iter: 1000; batch classifier loss: 0.151771; batch adversarial loss: 0.016711\n",
            "epoch 8; iter: 1200; batch classifier loss: 0.260911; batch adversarial loss: 0.219294\n",
            "epoch 8; iter: 1400; batch classifier loss: 0.170675; batch adversarial loss: 0.016503\n",
            "epoch 8; iter: 1600; batch classifier loss: 0.200999; batch adversarial loss: 0.016260\n",
            "epoch 9; iter: 0; batch classifier loss: 0.184345; batch adversarial loss: 0.197267\n",
            "epoch 9; iter: 200; batch classifier loss: 0.193268; batch adversarial loss: 0.149507\n",
            "epoch 9; iter: 400; batch classifier loss: 0.126437; batch adversarial loss: 0.084407\n",
            "epoch 9; iter: 600; batch classifier loss: 0.179015; batch adversarial loss: 0.017332\n",
            "epoch 9; iter: 800; batch classifier loss: 0.337743; batch adversarial loss: 0.015619\n",
            "epoch 9; iter: 1000; batch classifier loss: 0.145714; batch adversarial loss: 0.016753\n",
            "epoch 9; iter: 1200; batch classifier loss: 0.104986; batch adversarial loss: 0.083621\n",
            "epoch 9; iter: 1400; batch classifier loss: 0.202461; batch adversarial loss: 0.083359\n",
            "epoch 9; iter: 1600; batch classifier loss: 0.295460; batch adversarial loss: 0.152494\n",
            "epoch 10; iter: 0; batch classifier loss: 0.291106; batch adversarial loss: 0.152650\n",
            "epoch 10; iter: 200; batch classifier loss: 0.079813; batch adversarial loss: 0.015849\n",
            "epoch 10; iter: 400; batch classifier loss: 0.169504; batch adversarial loss: 0.082937\n",
            "epoch 10; iter: 600; batch classifier loss: 0.092967; batch adversarial loss: 0.081907\n",
            "epoch 10; iter: 800; batch classifier loss: 0.222976; batch adversarial loss: 0.018519\n",
            "epoch 10; iter: 1000; batch classifier loss: 0.297418; batch adversarial loss: 0.015055\n",
            "epoch 10; iter: 1200; batch classifier loss: 0.209694; batch adversarial loss: 0.014917\n",
            "epoch 10; iter: 1400; batch classifier loss: 0.167709; batch adversarial loss: 0.082612\n",
            "epoch 10; iter: 1600; batch classifier loss: 0.149897; batch adversarial loss: 0.015564\n",
            "epoch 11; iter: 0; batch classifier loss: 0.161270; batch adversarial loss: 0.150248\n",
            "epoch 11; iter: 200; batch classifier loss: 0.082356; batch adversarial loss: 0.081793\n",
            "epoch 11; iter: 400; batch classifier loss: 0.294276; batch adversarial loss: 0.017821\n",
            "epoch 11; iter: 600; batch classifier loss: 0.236296; batch adversarial loss: 0.016346\n",
            "epoch 11; iter: 800; batch classifier loss: 0.156953; batch adversarial loss: 0.014622\n",
            "epoch 11; iter: 1000; batch classifier loss: 0.314084; batch adversarial loss: 0.014642\n",
            "epoch 11; iter: 1200; batch classifier loss: 0.195138; batch adversarial loss: 0.017111\n",
            "epoch 11; iter: 1400; batch classifier loss: 0.295350; batch adversarial loss: 0.135540\n",
            "epoch 11; iter: 1600; batch classifier loss: 0.135199; batch adversarial loss: 0.082965\n",
            "epoch 12; iter: 0; batch classifier loss: 0.352928; batch adversarial loss: 0.151919\n",
            "epoch 12; iter: 200; batch classifier loss: 0.164526; batch adversarial loss: 0.015320\n",
            "epoch 12; iter: 400; batch classifier loss: 0.331119; batch adversarial loss: 0.082253\n",
            "epoch 12; iter: 600; batch classifier loss: 0.416819; batch adversarial loss: 0.148805\n",
            "epoch 12; iter: 800; batch classifier loss: 0.134830; batch adversarial loss: 0.149114\n",
            "epoch 12; iter: 1000; batch classifier loss: 0.222212; batch adversarial loss: 0.153516\n",
            "epoch 12; iter: 1200; batch classifier loss: 0.120830; batch adversarial loss: 0.080284\n",
            "epoch 12; iter: 1400; batch classifier loss: 0.205307; batch adversarial loss: 0.014540\n",
            "epoch 12; iter: 1600; batch classifier loss: 0.210751; batch adversarial loss: 0.015731\n",
            "epoch 13; iter: 0; batch classifier loss: 0.242940; batch adversarial loss: 0.080394\n",
            "epoch 13; iter: 200; batch classifier loss: 0.169520; batch adversarial loss: 0.081779\n",
            "epoch 13; iter: 400; batch classifier loss: 0.129014; batch adversarial loss: 0.015141\n",
            "epoch 13; iter: 600; batch classifier loss: 0.270401; batch adversarial loss: 0.013991\n",
            "epoch 13; iter: 800; batch classifier loss: 0.082121; batch adversarial loss: 0.150186\n",
            "epoch 13; iter: 1000; batch classifier loss: 0.268154; batch adversarial loss: 0.014903\n",
            "epoch 13; iter: 1200; batch classifier loss: 0.308109; batch adversarial loss: 0.015988\n",
            "epoch 13; iter: 1400; batch classifier loss: 0.252552; batch adversarial loss: 0.013593\n",
            "epoch 13; iter: 1600; batch classifier loss: 0.074770; batch adversarial loss: 0.085147\n",
            "epoch 14; iter: 0; batch classifier loss: 0.156815; batch adversarial loss: 0.081353\n",
            "epoch 14; iter: 200; batch classifier loss: 0.267763; batch adversarial loss: 0.015132\n",
            "epoch 14; iter: 400; batch classifier loss: 0.296401; batch adversarial loss: 0.151707\n",
            "epoch 14; iter: 600; batch classifier loss: 0.078012; batch adversarial loss: 0.212348\n",
            "epoch 14; iter: 800; batch classifier loss: 0.235481; batch adversarial loss: 0.016950\n",
            "epoch 14; iter: 1000; batch classifier loss: 0.237324; batch adversarial loss: 0.082843\n",
            "epoch 14; iter: 1200; batch classifier loss: 0.123508; batch adversarial loss: 0.147822\n",
            "epoch 14; iter: 1400; batch classifier loss: 0.178272; batch adversarial loss: 0.150246\n",
            "epoch 14; iter: 1600; batch classifier loss: 0.157403; batch adversarial loss: 0.082510\n",
            "epoch 15; iter: 0; batch classifier loss: 0.083518; batch adversarial loss: 0.014366\n",
            "epoch 15; iter: 200; batch classifier loss: 0.308097; batch adversarial loss: 0.081725\n",
            "epoch 15; iter: 400; batch classifier loss: 0.204235; batch adversarial loss: 0.068802\n",
            "epoch 15; iter: 600; batch classifier loss: 0.299629; batch adversarial loss: 0.083657\n",
            "epoch 15; iter: 800; batch classifier loss: 0.268482; batch adversarial loss: 0.079300\n",
            "epoch 15; iter: 1000; batch classifier loss: 0.278844; batch adversarial loss: 0.215368\n",
            "epoch 15; iter: 1200; batch classifier loss: 0.146036; batch adversarial loss: 0.016233\n",
            "epoch 15; iter: 1400; batch classifier loss: 0.109078; batch adversarial loss: 0.192615\n",
            "epoch 15; iter: 1600; batch classifier loss: 0.220287; batch adversarial loss: 0.084734\n",
            "epoch 16; iter: 0; batch classifier loss: 0.081414; batch adversarial loss: 0.013843\n",
            "epoch 16; iter: 200; batch classifier loss: 0.181134; batch adversarial loss: 0.085078\n",
            "epoch 16; iter: 400; batch classifier loss: 0.354639; batch adversarial loss: 0.055041\n",
            "epoch 16; iter: 600; batch classifier loss: 0.255864; batch adversarial loss: 0.149596\n",
            "epoch 16; iter: 800; batch classifier loss: 0.290150; batch adversarial loss: 0.082575\n",
            "epoch 16; iter: 1000; batch classifier loss: 0.262381; batch adversarial loss: 0.015172\n",
            "epoch 16; iter: 1200; batch classifier loss: 0.159844; batch adversarial loss: 0.015062\n",
            "epoch 16; iter: 1400; batch classifier loss: 0.074595; batch adversarial loss: 0.015065\n",
            "epoch 16; iter: 1600; batch classifier loss: 0.115965; batch adversarial loss: 0.016298\n",
            "epoch 17; iter: 0; batch classifier loss: 0.262777; batch adversarial loss: 0.015473\n",
            "epoch 17; iter: 200; batch classifier loss: 0.143678; batch adversarial loss: 0.085314\n",
            "epoch 17; iter: 400; batch classifier loss: 0.155685; batch adversarial loss: 0.151389\n",
            "epoch 17; iter: 600; batch classifier loss: 0.167303; batch adversarial loss: 0.084778\n",
            "epoch 17; iter: 800; batch classifier loss: 0.155854; batch adversarial loss: 0.014094\n",
            "epoch 17; iter: 1000; batch classifier loss: 0.414321; batch adversarial loss: 0.016971\n",
            "epoch 17; iter: 1200; batch classifier loss: 0.150029; batch adversarial loss: 0.081855\n",
            "epoch 17; iter: 1400; batch classifier loss: 0.334903; batch adversarial loss: 0.015448\n",
            "epoch 17; iter: 1600; batch classifier loss: 0.149777; batch adversarial loss: 0.150655\n",
            "epoch 18; iter: 0; batch classifier loss: 0.251835; batch adversarial loss: 0.083008\n",
            "epoch 18; iter: 200; batch classifier loss: 0.220112; batch adversarial loss: 0.083403\n",
            "epoch 18; iter: 400; batch classifier loss: 0.277678; batch adversarial loss: 0.017673\n",
            "epoch 18; iter: 600; batch classifier loss: 0.063256; batch adversarial loss: 0.015625\n",
            "epoch 18; iter: 800; batch classifier loss: 0.208849; batch adversarial loss: 0.082782\n",
            "epoch 18; iter: 1000; batch classifier loss: 0.295088; batch adversarial loss: 0.084190\n",
            "epoch 18; iter: 1200; batch classifier loss: 0.258266; batch adversarial loss: 0.014262\n",
            "epoch 18; iter: 1400; batch classifier loss: 0.136340; batch adversarial loss: 0.015310\n",
            "epoch 18; iter: 1600; batch classifier loss: 0.134924; batch adversarial loss: 0.014276\n",
            "epoch 19; iter: 0; batch classifier loss: 0.244549; batch adversarial loss: 0.017304\n",
            "epoch 19; iter: 200; batch classifier loss: 0.280965; batch adversarial loss: 0.082255\n",
            "epoch 19; iter: 400; batch classifier loss: 0.061229; batch adversarial loss: 0.082945\n",
            "epoch 19; iter: 600; batch classifier loss: 0.248268; batch adversarial loss: 0.082306\n",
            "epoch 19; iter: 800; batch classifier loss: 0.111767; batch adversarial loss: 0.015765\n",
            "epoch 19; iter: 1000; batch classifier loss: 0.146302; batch adversarial loss: 0.145827\n",
            "epoch 19; iter: 1200; batch classifier loss: 0.100529; batch adversarial loss: 0.150173\n",
            "epoch 19; iter: 1400; batch classifier loss: 0.085494; batch adversarial loss: 0.013907\n",
            "epoch 19; iter: 1600; batch classifier loss: 0.205614; batch adversarial loss: 0.013562\n",
            "epoch 20; iter: 0; batch classifier loss: 0.080362; batch adversarial loss: 0.082366\n",
            "epoch 20; iter: 200; batch classifier loss: 0.252897; batch adversarial loss: 0.016150\n",
            "epoch 20; iter: 400; batch classifier loss: 0.102524; batch adversarial loss: 0.015089\n",
            "epoch 20; iter: 600; batch classifier loss: 0.141948; batch adversarial loss: 0.189577\n",
            "epoch 20; iter: 800; batch classifier loss: 0.194294; batch adversarial loss: 0.082066\n",
            "epoch 20; iter: 1000; batch classifier loss: 0.288960; batch adversarial loss: 0.150155\n",
            "epoch 20; iter: 1200; batch classifier loss: 0.293323; batch adversarial loss: 0.082279\n",
            "epoch 20; iter: 1400; batch classifier loss: 0.182251; batch adversarial loss: 0.014092\n",
            "epoch 20; iter: 1600; batch classifier loss: 0.251010; batch adversarial loss: 0.016118\n",
            "epoch 21; iter: 0; batch classifier loss: 0.192123; batch adversarial loss: 0.134576\n",
            "epoch 21; iter: 200; batch classifier loss: 0.184468; batch adversarial loss: 0.082353\n",
            "epoch 21; iter: 400; batch classifier loss: 0.163144; batch adversarial loss: 0.015042\n",
            "epoch 21; iter: 600; batch classifier loss: 0.164306; batch adversarial loss: 0.014343\n",
            "epoch 21; iter: 800; batch classifier loss: 0.163000; batch adversarial loss: 0.081649\n",
            "epoch 21; iter: 1000; batch classifier loss: 0.114386; batch adversarial loss: 0.150752\n",
            "epoch 21; iter: 1200; batch classifier loss: 0.160234; batch adversarial loss: 0.015518\n",
            "epoch 21; iter: 1400; batch classifier loss: 0.136638; batch adversarial loss: 0.150984\n",
            "epoch 21; iter: 1600; batch classifier loss: 0.245376; batch adversarial loss: 0.017111\n",
            "epoch 22; iter: 0; batch classifier loss: 0.161703; batch adversarial loss: 0.216760\n",
            "epoch 22; iter: 200; batch classifier loss: 0.171959; batch adversarial loss: 0.082093\n",
            "epoch 22; iter: 400; batch classifier loss: 0.191412; batch adversarial loss: 0.014566\n",
            "epoch 22; iter: 600; batch classifier loss: 0.211263; batch adversarial loss: 0.015277\n",
            "epoch 22; iter: 800; batch classifier loss: 0.386617; batch adversarial loss: 0.015695\n",
            "epoch 22; iter: 1000; batch classifier loss: 0.164966; batch adversarial loss: 0.085275\n",
            "epoch 22; iter: 1200; batch classifier loss: 0.261007; batch adversarial loss: 0.147785\n",
            "epoch 22; iter: 1400; batch classifier loss: 0.336563; batch adversarial loss: 0.149032\n",
            "epoch 22; iter: 1600; batch classifier loss: 0.158536; batch adversarial loss: 0.149636\n",
            "epoch 23; iter: 0; batch classifier loss: 0.173097; batch adversarial loss: 0.149021\n",
            "epoch 23; iter: 200; batch classifier loss: 0.124261; batch adversarial loss: 0.146876\n",
            "epoch 23; iter: 400; batch classifier loss: 0.154130; batch adversarial loss: 0.014314\n",
            "epoch 23; iter: 600; batch classifier loss: 0.371909; batch adversarial loss: 0.014895\n",
            "epoch 23; iter: 800; batch classifier loss: 0.108022; batch adversarial loss: 0.015779\n",
            "epoch 23; iter: 1000; batch classifier loss: 0.151956; batch adversarial loss: 0.017822\n",
            "epoch 23; iter: 1200; batch classifier loss: 0.168676; batch adversarial loss: 0.150224\n",
            "epoch 23; iter: 1400; batch classifier loss: 0.228586; batch adversarial loss: 0.015822\n",
            "epoch 23; iter: 1600; batch classifier loss: 0.169328; batch adversarial loss: 0.015068\n",
            "epoch 24; iter: 0; batch classifier loss: 0.291764; batch adversarial loss: 0.015622\n",
            "epoch 24; iter: 200; batch classifier loss: 0.190084; batch adversarial loss: 0.082007\n",
            "epoch 24; iter: 400; batch classifier loss: 0.263344; batch adversarial loss: 0.014669\n",
            "epoch 24; iter: 600; batch classifier loss: 0.196033; batch adversarial loss: 0.016379\n",
            "epoch 24; iter: 800; batch classifier loss: 0.162635; batch adversarial loss: 0.082658\n",
            "epoch 24; iter: 1000; batch classifier loss: 0.166434; batch adversarial loss: 0.014893\n",
            "epoch 24; iter: 1200; batch classifier loss: 0.209561; batch adversarial loss: 0.150414\n",
            "epoch 24; iter: 1400; batch classifier loss: 0.134600; batch adversarial loss: 0.061523\n",
            "epoch 24; iter: 1600; batch classifier loss: 0.240852; batch adversarial loss: 0.084579\n",
            "epoch 25; iter: 0; batch classifier loss: 0.316085; batch adversarial loss: 0.083986\n",
            "epoch 25; iter: 200; batch classifier loss: 0.207352; batch adversarial loss: 0.219088\n",
            "epoch 25; iter: 400; batch classifier loss: 0.150024; batch adversarial loss: 0.080888\n",
            "epoch 25; iter: 600; batch classifier loss: 0.122677; batch adversarial loss: 0.148553\n",
            "epoch 25; iter: 800; batch classifier loss: 0.236288; batch adversarial loss: 0.015381\n",
            "epoch 25; iter: 1000; batch classifier loss: 0.157407; batch adversarial loss: 0.150568\n",
            "epoch 25; iter: 1200; batch classifier loss: 0.113707; batch adversarial loss: 0.149512\n",
            "epoch 25; iter: 1400; batch classifier loss: 0.263462; batch adversarial loss: 0.017078\n",
            "epoch 25; iter: 1600; batch classifier loss: 0.408164; batch adversarial loss: 0.014800\n",
            "epoch 26; iter: 0; batch classifier loss: 0.177492; batch adversarial loss: 0.016881\n",
            "epoch 26; iter: 200; batch classifier loss: 0.223140; batch adversarial loss: 0.215431\n",
            "epoch 26; iter: 400; batch classifier loss: 0.125920; batch adversarial loss: 0.014661\n",
            "epoch 26; iter: 600; batch classifier loss: 0.175876; batch adversarial loss: 0.146044\n",
            "epoch 26; iter: 800; batch classifier loss: 0.511510; batch adversarial loss: 0.215221\n",
            "epoch 26; iter: 1000; batch classifier loss: 0.236285; batch adversarial loss: 0.151621\n",
            "epoch 26; iter: 1200; batch classifier loss: 0.268323; batch adversarial loss: 0.084100\n",
            "epoch 26; iter: 1400; batch classifier loss: 0.199557; batch adversarial loss: 0.059278\n",
            "epoch 26; iter: 1600; batch classifier loss: 0.207936; batch adversarial loss: 0.217816\n",
            "epoch 27; iter: 0; batch classifier loss: 0.139089; batch adversarial loss: 0.152447\n",
            "epoch 27; iter: 200; batch classifier loss: 0.103075; batch adversarial loss: 0.283430\n",
            "epoch 27; iter: 400; batch classifier loss: 0.292523; batch adversarial loss: 0.149667\n",
            "epoch 27; iter: 600; batch classifier loss: 0.245572; batch adversarial loss: 0.017776\n",
            "epoch 27; iter: 800; batch classifier loss: 0.117313; batch adversarial loss: 0.015158\n",
            "epoch 27; iter: 1000; batch classifier loss: 0.182808; batch adversarial loss: 0.016706\n",
            "epoch 27; iter: 1200; batch classifier loss: 0.136486; batch adversarial loss: 0.014822\n",
            "epoch 27; iter: 1400; batch classifier loss: 0.223743; batch adversarial loss: 0.015624\n",
            "epoch 27; iter: 1600; batch classifier loss: 0.358458; batch adversarial loss: 0.014451\n",
            "epoch 28; iter: 0; batch classifier loss: 0.160705; batch adversarial loss: 0.015202\n",
            "epoch 28; iter: 200; batch classifier loss: 0.280314; batch adversarial loss: 0.083181\n",
            "epoch 28; iter: 400; batch classifier loss: 0.217402; batch adversarial loss: 0.015855\n",
            "epoch 28; iter: 600; batch classifier loss: 0.116408; batch adversarial loss: 0.013593\n",
            "epoch 28; iter: 800; batch classifier loss: 0.168116; batch adversarial loss: 0.082573\n",
            "epoch 28; iter: 1000; batch classifier loss: 0.242898; batch adversarial loss: 0.148375\n",
            "epoch 28; iter: 1200; batch classifier loss: 0.109991; batch adversarial loss: 0.082438\n",
            "epoch 28; iter: 1400; batch classifier loss: 0.115045; batch adversarial loss: 0.013653\n",
            "epoch 28; iter: 1600; batch classifier loss: 0.128911; batch adversarial loss: 0.013745\n",
            "epoch 29; iter: 0; batch classifier loss: 0.426325; batch adversarial loss: 0.149631\n",
            "epoch 29; iter: 200; batch classifier loss: 0.062277; batch adversarial loss: 0.015116\n",
            "epoch 29; iter: 400; batch classifier loss: 0.220145; batch adversarial loss: 0.015085\n",
            "epoch 29; iter: 600; batch classifier loss: 0.272149; batch adversarial loss: 0.015959\n",
            "epoch 29; iter: 800; batch classifier loss: 0.338245; batch adversarial loss: 0.016297\n",
            "epoch 29; iter: 1000; batch classifier loss: 0.214487; batch adversarial loss: 0.014990\n",
            "epoch 29; iter: 1200; batch classifier loss: 0.120069; batch adversarial loss: 0.081067\n",
            "epoch 29; iter: 1400; batch classifier loss: 0.278791; batch adversarial loss: 0.014851\n",
            "epoch 29; iter: 1600; batch classifier loss: 0.326015; batch adversarial loss: 0.015203\n",
            "epoch 30; iter: 0; batch classifier loss: 0.207194; batch adversarial loss: 0.013907\n",
            "epoch 30; iter: 200; batch classifier loss: 0.296433; batch adversarial loss: 0.085231\n",
            "epoch 30; iter: 400; batch classifier loss: 0.075739; batch adversarial loss: 0.081494\n",
            "epoch 30; iter: 600; batch classifier loss: 0.141828; batch adversarial loss: 0.084144\n",
            "epoch 30; iter: 800; batch classifier loss: 0.323174; batch adversarial loss: 0.076143\n",
            "epoch 30; iter: 1000; batch classifier loss: 0.236335; batch adversarial loss: 0.016066\n",
            "epoch 30; iter: 1200; batch classifier loss: 0.180072; batch adversarial loss: 0.013865\n",
            "epoch 30; iter: 1400; batch classifier loss: 0.176467; batch adversarial loss: 0.085996\n",
            "epoch 30; iter: 1600; batch classifier loss: 0.132742; batch adversarial loss: 0.081719\n",
            "epoch 31; iter: 0; batch classifier loss: 0.219855; batch adversarial loss: 0.120627\n",
            "epoch 31; iter: 200; batch classifier loss: 0.227998; batch adversarial loss: 0.015537\n",
            "epoch 31; iter: 400; batch classifier loss: 0.119567; batch adversarial loss: 0.015013\n",
            "epoch 31; iter: 600; batch classifier loss: 0.291838; batch adversarial loss: 0.079001\n",
            "epoch 31; iter: 800; batch classifier loss: 0.275051; batch adversarial loss: 0.082652\n",
            "epoch 31; iter: 1000; batch classifier loss: 0.393428; batch adversarial loss: 0.084069\n",
            "epoch 31; iter: 1200; batch classifier loss: 0.224158; batch adversarial loss: 0.017375\n",
            "epoch 31; iter: 1400; batch classifier loss: 0.112717; batch adversarial loss: 0.150902\n",
            "epoch 31; iter: 1600; batch classifier loss: 0.078942; batch adversarial loss: 0.081139\n",
            "epoch 32; iter: 0; batch classifier loss: 0.418920; batch adversarial loss: 0.016199\n",
            "epoch 32; iter: 200; batch classifier loss: 0.138734; batch adversarial loss: 0.015494\n",
            "epoch 32; iter: 400; batch classifier loss: 0.239715; batch adversarial loss: 0.084594\n",
            "epoch 32; iter: 600; batch classifier loss: 0.097339; batch adversarial loss: 0.082713\n",
            "epoch 32; iter: 800; batch classifier loss: 0.108288; batch adversarial loss: 0.014339\n",
            "epoch 32; iter: 1000; batch classifier loss: 0.244531; batch adversarial loss: 0.206993\n",
            "epoch 32; iter: 1200; batch classifier loss: 0.138090; batch adversarial loss: 0.083357\n",
            "epoch 32; iter: 1400; batch classifier loss: 0.258151; batch adversarial loss: 0.217313\n",
            "epoch 32; iter: 1600; batch classifier loss: 0.289794; batch adversarial loss: 0.136621\n",
            "epoch 33; iter: 0; batch classifier loss: 0.092952; batch adversarial loss: 0.148316\n",
            "epoch 33; iter: 200; batch classifier loss: 0.146220; batch adversarial loss: 0.014656\n",
            "epoch 33; iter: 400; batch classifier loss: 0.056436; batch adversarial loss: 0.014480\n",
            "epoch 33; iter: 600; batch classifier loss: 0.198902; batch adversarial loss: 0.082162\n",
            "epoch 33; iter: 800; batch classifier loss: 0.151616; batch adversarial loss: 0.081578\n",
            "epoch 33; iter: 1000; batch classifier loss: 0.193791; batch adversarial loss: 0.014273\n",
            "epoch 33; iter: 1200; batch classifier loss: 0.229665; batch adversarial loss: 0.016680\n",
            "epoch 33; iter: 1400; batch classifier loss: 0.231744; batch adversarial loss: 0.152291\n",
            "epoch 33; iter: 1600; batch classifier loss: 0.280484; batch adversarial loss: 0.081095\n",
            "epoch 34; iter: 0; batch classifier loss: 0.181493; batch adversarial loss: 0.082448\n",
            "epoch 34; iter: 200; batch classifier loss: 0.096485; batch adversarial loss: 0.081577\n",
            "epoch 34; iter: 400; batch classifier loss: 0.267653; batch adversarial loss: 0.015991\n",
            "epoch 34; iter: 600; batch classifier loss: 0.340274; batch adversarial loss: 0.015340\n",
            "epoch 34; iter: 800; batch classifier loss: 0.141154; batch adversarial loss: 0.081724\n",
            "epoch 34; iter: 1000; batch classifier loss: 0.202529; batch adversarial loss: 0.083019\n",
            "epoch 34; iter: 1200; batch classifier loss: 0.112716; batch adversarial loss: 0.016244\n",
            "epoch 34; iter: 1400; batch classifier loss: 0.244322; batch adversarial loss: 0.082875\n",
            "epoch 34; iter: 1600; batch classifier loss: 0.256401; batch adversarial loss: 0.014834\n",
            "epoch 35; iter: 0; batch classifier loss: 0.213337; batch adversarial loss: 0.267890\n",
            "epoch 35; iter: 200; batch classifier loss: 0.421424; batch adversarial loss: 0.082043\n",
            "epoch 35; iter: 400; batch classifier loss: 0.346276; batch adversarial loss: 0.151695\n",
            "epoch 35; iter: 600; batch classifier loss: 0.209459; batch adversarial loss: 0.015365\n",
            "epoch 35; iter: 800; batch classifier loss: 0.320750; batch adversarial loss: 0.204464\n",
            "epoch 35; iter: 1000; batch classifier loss: 0.129465; batch adversarial loss: 0.139748\n",
            "epoch 35; iter: 1200; batch classifier loss: 0.138330; batch adversarial loss: 0.150193\n",
            "epoch 35; iter: 1400; batch classifier loss: 0.171844; batch adversarial loss: 0.149046\n",
            "epoch 35; iter: 1600; batch classifier loss: 0.274195; batch adversarial loss: 0.067189\n",
            "epoch 36; iter: 0; batch classifier loss: 0.194255; batch adversarial loss: 0.148733\n",
            "epoch 36; iter: 200; batch classifier loss: 0.122542; batch adversarial loss: 0.150046\n",
            "epoch 36; iter: 400; batch classifier loss: 0.322678; batch adversarial loss: 0.084005\n",
            "epoch 36; iter: 600; batch classifier loss: 0.154933; batch adversarial loss: 0.151814\n",
            "epoch 36; iter: 800; batch classifier loss: 0.129130; batch adversarial loss: 0.082368\n",
            "epoch 36; iter: 1000; batch classifier loss: 0.169506; batch adversarial loss: 0.218051\n",
            "epoch 36; iter: 1200; batch classifier loss: 0.217543; batch adversarial loss: 0.014427\n",
            "epoch 36; iter: 1400; batch classifier loss: 0.142842; batch adversarial loss: 0.082634\n",
            "epoch 36; iter: 1600; batch classifier loss: 0.158925; batch adversarial loss: 0.014942\n",
            "epoch 37; iter: 0; batch classifier loss: 0.212573; batch adversarial loss: 0.083892\n",
            "epoch 37; iter: 200; batch classifier loss: 0.238833; batch adversarial loss: 0.077421\n",
            "epoch 37; iter: 400; batch classifier loss: 0.204762; batch adversarial loss: 0.217137\n",
            "epoch 37; iter: 600; batch classifier loss: 0.123255; batch adversarial loss: 0.015442\n",
            "epoch 37; iter: 800; batch classifier loss: 0.372620; batch adversarial loss: 0.080706\n",
            "epoch 37; iter: 1000; batch classifier loss: 0.280031; batch adversarial loss: 0.015914\n",
            "epoch 37; iter: 1200; batch classifier loss: 0.196483; batch adversarial loss: 0.015685\n",
            "epoch 37; iter: 1400; batch classifier loss: 0.259750; batch adversarial loss: 0.085810\n",
            "epoch 37; iter: 1600; batch classifier loss: 0.150639; batch adversarial loss: 0.017399\n",
            "epoch 38; iter: 0; batch classifier loss: 0.291985; batch adversarial loss: 0.214790\n",
            "epoch 38; iter: 200; batch classifier loss: 0.166286; batch adversarial loss: 0.082280\n",
            "epoch 38; iter: 400; batch classifier loss: 0.119361; batch adversarial loss: 0.015184\n",
            "epoch 38; iter: 600; batch classifier loss: 0.130805; batch adversarial loss: 0.082631\n",
            "epoch 38; iter: 800; batch classifier loss: 0.244843; batch adversarial loss: 0.066771\n",
            "epoch 38; iter: 1000; batch classifier loss: 0.250412; batch adversarial loss: 0.218488\n",
            "epoch 38; iter: 1200; batch classifier loss: 0.249444; batch adversarial loss: 0.081986\n",
            "epoch 38; iter: 1400; batch classifier loss: 0.158580; batch adversarial loss: 0.084340\n",
            "epoch 38; iter: 1600; batch classifier loss: 0.139947; batch adversarial loss: 0.017162\n",
            "epoch 39; iter: 0; batch classifier loss: 0.236382; batch adversarial loss: 0.144410\n",
            "epoch 39; iter: 200; batch classifier loss: 0.232327; batch adversarial loss: 0.218382\n",
            "epoch 39; iter: 400; batch classifier loss: 0.342958; batch adversarial loss: 0.077894\n",
            "epoch 39; iter: 600; batch classifier loss: 0.412158; batch adversarial loss: 0.083100\n",
            "epoch 39; iter: 800; batch classifier loss: 0.342760; batch adversarial loss: 0.082321\n",
            "epoch 39; iter: 1000; batch classifier loss: 0.118055; batch adversarial loss: 0.015076\n",
            "epoch 39; iter: 1200; batch classifier loss: 0.215731; batch adversarial loss: 0.065157\n",
            "epoch 39; iter: 1400; batch classifier loss: 0.196250; batch adversarial loss: 0.016822\n",
            "epoch 39; iter: 1600; batch classifier loss: 0.202308; batch adversarial loss: 0.083586\n",
            "epoch 40; iter: 0; batch classifier loss: 0.096321; batch adversarial loss: 0.081603\n",
            "epoch 40; iter: 200; batch classifier loss: 0.177247; batch adversarial loss: 0.083120\n",
            "epoch 40; iter: 400; batch classifier loss: 0.103036; batch adversarial loss: 0.016422\n",
            "epoch 40; iter: 600; batch classifier loss: 0.202691; batch adversarial loss: 0.018197\n",
            "epoch 40; iter: 800; batch classifier loss: 0.232398; batch adversarial loss: 0.081818\n",
            "epoch 40; iter: 1000; batch classifier loss: 0.349721; batch adversarial loss: 0.082922\n",
            "epoch 40; iter: 1200; batch classifier loss: 0.243188; batch adversarial loss: 0.014734\n",
            "epoch 40; iter: 1400; batch classifier loss: 0.194538; batch adversarial loss: 0.015121\n",
            "epoch 40; iter: 1600; batch classifier loss: 0.092808; batch adversarial loss: 0.080166\n",
            "epoch 41; iter: 0; batch classifier loss: 0.211839; batch adversarial loss: 0.146701\n",
            "epoch 41; iter: 200; batch classifier loss: 0.257941; batch adversarial loss: 0.016399\n",
            "epoch 41; iter: 400; batch classifier loss: 0.154059; batch adversarial loss: 0.082443\n",
            "epoch 41; iter: 600; batch classifier loss: 0.161749; batch adversarial loss: 0.150055\n",
            "epoch 41; iter: 800; batch classifier loss: 0.186807; batch adversarial loss: 0.148807\n",
            "epoch 41; iter: 1000; batch classifier loss: 0.132376; batch adversarial loss: 0.352515\n",
            "epoch 41; iter: 1200; batch classifier loss: 0.247532; batch adversarial loss: 0.075351\n",
            "epoch 41; iter: 1400; batch classifier loss: 0.176374; batch adversarial loss: 0.015657\n",
            "epoch 41; iter: 1600; batch classifier loss: 0.182953; batch adversarial loss: 0.062755\n",
            "epoch 42; iter: 0; batch classifier loss: 0.121875; batch adversarial loss: 0.082273\n",
            "epoch 42; iter: 200; batch classifier loss: 0.258240; batch adversarial loss: 0.082645\n",
            "epoch 42; iter: 400; batch classifier loss: 0.309604; batch adversarial loss: 0.150730\n",
            "epoch 42; iter: 600; batch classifier loss: 0.153929; batch adversarial loss: 0.016934\n",
            "epoch 42; iter: 800; batch classifier loss: 0.196992; batch adversarial loss: 0.082600\n",
            "epoch 42; iter: 1000; batch classifier loss: 0.314322; batch adversarial loss: 0.014816\n",
            "epoch 42; iter: 1200; batch classifier loss: 0.341457; batch adversarial loss: 0.083468\n",
            "epoch 42; iter: 1400; batch classifier loss: 0.227145; batch adversarial loss: 0.082705\n",
            "epoch 42; iter: 1600; batch classifier loss: 0.199800; batch adversarial loss: 0.082149\n",
            "epoch 43; iter: 0; batch classifier loss: 0.339170; batch adversarial loss: 0.137871\n",
            "epoch 43; iter: 200; batch classifier loss: 0.329180; batch adversarial loss: 0.078217\n",
            "epoch 43; iter: 400; batch classifier loss: 0.175815; batch adversarial loss: 0.013955\n",
            "epoch 43; iter: 600; batch classifier loss: 0.252632; batch adversarial loss: 0.082379\n",
            "epoch 43; iter: 800; batch classifier loss: 0.191050; batch adversarial loss: 0.014534\n",
            "epoch 43; iter: 1000; batch classifier loss: 0.336511; batch adversarial loss: 0.081802\n",
            "epoch 43; iter: 1200; batch classifier loss: 0.164413; batch adversarial loss: 0.013943\n",
            "epoch 43; iter: 1400; batch classifier loss: 0.238706; batch adversarial loss: 0.015825\n",
            "epoch 43; iter: 1600; batch classifier loss: 0.314705; batch adversarial loss: 0.146665\n",
            "epoch 44; iter: 0; batch classifier loss: 0.294710; batch adversarial loss: 0.083439\n",
            "epoch 44; iter: 200; batch classifier loss: 0.171099; batch adversarial loss: 0.149726\n",
            "epoch 44; iter: 400; batch classifier loss: 0.176037; batch adversarial loss: 0.014849\n",
            "epoch 44; iter: 600; batch classifier loss: 0.173904; batch adversarial loss: 0.080934\n",
            "epoch 44; iter: 800; batch classifier loss: 0.146539; batch adversarial loss: 0.082913\n",
            "epoch 44; iter: 1000; batch classifier loss: 0.188110; batch adversarial loss: 0.014526\n",
            "epoch 44; iter: 1200; batch classifier loss: 0.259493; batch adversarial loss: 0.015606\n",
            "epoch 44; iter: 1400; batch classifier loss: 0.172267; batch adversarial loss: 0.136848\n",
            "epoch 44; iter: 1600; batch classifier loss: 0.090996; batch adversarial loss: 0.014314\n",
            "epoch 45; iter: 0; batch classifier loss: 0.399166; batch adversarial loss: 0.015773\n",
            "epoch 45; iter: 200; batch classifier loss: 0.088309; batch adversarial loss: 0.081297\n",
            "epoch 45; iter: 400; batch classifier loss: 0.145105; batch adversarial loss: 0.015036\n",
            "epoch 45; iter: 600; batch classifier loss: 0.201136; batch adversarial loss: 0.015196\n",
            "epoch 45; iter: 800; batch classifier loss: 0.213106; batch adversarial loss: 0.138920\n",
            "epoch 45; iter: 1000; batch classifier loss: 0.190265; batch adversarial loss: 0.082038\n",
            "epoch 45; iter: 1200; batch classifier loss: 0.200556; batch adversarial loss: 0.083444\n",
            "epoch 45; iter: 1400; batch classifier loss: 0.331767; batch adversarial loss: 0.015167\n",
            "epoch 45; iter: 1600; batch classifier loss: 0.133602; batch adversarial loss: 0.149496\n",
            "epoch 46; iter: 0; batch classifier loss: 0.164404; batch adversarial loss: 0.332606\n",
            "epoch 46; iter: 200; batch classifier loss: 0.240835; batch adversarial loss: 0.083617\n",
            "epoch 46; iter: 400; batch classifier loss: 0.198560; batch adversarial loss: 0.076450\n",
            "epoch 46; iter: 600; batch classifier loss: 0.333560; batch adversarial loss: 0.015825\n",
            "epoch 46; iter: 800; batch classifier loss: 0.299519; batch adversarial loss: 0.081461\n",
            "epoch 46; iter: 1000; batch classifier loss: 0.213008; batch adversarial loss: 0.015657\n",
            "epoch 46; iter: 1200; batch classifier loss: 0.071729; batch adversarial loss: 0.014632\n",
            "epoch 46; iter: 1400; batch classifier loss: 0.205503; batch adversarial loss: 0.083716\n",
            "epoch 46; iter: 1600; batch classifier loss: 0.149682; batch adversarial loss: 0.014623\n",
            "epoch 47; iter: 0; batch classifier loss: 0.235267; batch adversarial loss: 0.082377\n",
            "epoch 47; iter: 200; batch classifier loss: 0.128337; batch adversarial loss: 0.016128\n",
            "epoch 47; iter: 400; batch classifier loss: 0.199923; batch adversarial loss: 0.015803\n",
            "epoch 47; iter: 600; batch classifier loss: 0.289427; batch adversarial loss: 0.015072\n",
            "epoch 47; iter: 800; batch classifier loss: 0.292375; batch adversarial loss: 0.015760\n",
            "epoch 47; iter: 1000; batch classifier loss: 0.196908; batch adversarial loss: 0.149148\n",
            "epoch 47; iter: 1200; batch classifier loss: 0.171405; batch adversarial loss: 0.013883\n",
            "epoch 47; iter: 1400; batch classifier loss: 0.209587; batch adversarial loss: 0.084588\n",
            "epoch 47; iter: 1600; batch classifier loss: 0.233326; batch adversarial loss: 0.015927\n",
            "epoch 48; iter: 0; batch classifier loss: 0.091780; batch adversarial loss: 0.081943\n",
            "epoch 48; iter: 200; batch classifier loss: 0.174746; batch adversarial loss: 0.014472\n",
            "epoch 48; iter: 400; batch classifier loss: 0.275757; batch adversarial loss: 0.015177\n",
            "epoch 48; iter: 600; batch classifier loss: 0.088924; batch adversarial loss: 0.015417\n",
            "epoch 48; iter: 800; batch classifier loss: 0.112970; batch adversarial loss: 0.014721\n",
            "epoch 48; iter: 1000; batch classifier loss: 0.214450; batch adversarial loss: 0.082212\n",
            "epoch 48; iter: 1200; batch classifier loss: 0.094316; batch adversarial loss: 0.014344\n",
            "epoch 48; iter: 1400; batch classifier loss: 0.166279; batch adversarial loss: 0.151819\n",
            "epoch 48; iter: 1600; batch classifier loss: 0.223672; batch adversarial loss: 0.014678\n",
            "epoch 49; iter: 0; batch classifier loss: 0.188611; batch adversarial loss: 0.212743\n",
            "epoch 49; iter: 200; batch classifier loss: 0.224709; batch adversarial loss: 0.015391\n",
            "epoch 49; iter: 400; batch classifier loss: 0.097781; batch adversarial loss: 0.214597\n",
            "epoch 49; iter: 600; batch classifier loss: 0.217644; batch adversarial loss: 0.082556\n",
            "epoch 49; iter: 800; batch classifier loss: 0.141368; batch adversarial loss: 0.148948\n",
            "epoch 49; iter: 1000; batch classifier loss: 0.363861; batch adversarial loss: 0.015440\n",
            "epoch 49; iter: 1200; batch classifier loss: 0.075443; batch adversarial loss: 0.150976\n",
            "epoch 49; iter: 1400; batch classifier loss: 0.322164; batch adversarial loss: 0.014657\n",
            "epoch 49; iter: 1600; batch classifier loss: 0.214881; batch adversarial loss: 0.015324\n"
          ]
        }
      ],
      "source": [
        "results['AdversarialDebiasing'] = train_adversarial_debiasing(X_train, y_train, prot_train, X_test, y_test, prot_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "dfe95a93-6a75-4c08-827e-abb7f40d70d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfe95a93-6a75-4c08-827e-abb7f40d70d8",
        "outputId": "40bbd21c-539d-4e6c-c03e-38f3532e30b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fairness Evaluation Across Compatible AIF360 In-processing Algorithms\n",
            "\n",
            "🔹 GerryFair\n",
            "  accuracy: 0.9332\n",
            "  disparate_impact: 0.9575\n",
            "  statistical_parity_difference: -0.0424\n",
            "  equal_opportunity_difference: -0.0313\n",
            "\n",
            "🔹 PrejudiceRemover\n",
            "  accuracy: 0.0659\n",
            "  disparate_impact: 0.0000\n",
            "  statistical_parity_difference: -0.0045\n",
            "  equal_opportunity_difference: -0.0019\n",
            "\n",
            "🔹 ExponentiatedGradient\n",
            "  accuracy: 0.9340\n",
            "  disparate_impact: 0.9880\n",
            "  statistical_parity_difference: -0.0119\n",
            "  equal_opportunity_difference: -0.0084\n",
            "\n",
            "🔹 GridSearch\n",
            "  accuracy: 0.9338\n",
            "  disparate_impact: 1.0035\n",
            "  statistical_parity_difference: 0.0034\n",
            "  equal_opportunity_difference: 0.0015\n",
            "\n",
            "🔹 AdversarialDebiasing\n",
            "  accuracy: 0.9342\n",
            "  disparate_impact: 1.0195\n",
            "  statistical_parity_difference: 0.0188\n",
            "  equal_opportunity_difference: 0.0100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Fairness Evaluation Across Compatible AIF360 In-processing Algorithms\\n\")\n",
        "for model, metrics in results.items():\n",
        "    print(f\"🔹 {model}\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        print(f\"  {metric_name}: {value:.4f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "744e0fad-36c1-4f97-ab4d-f236f426a79e",
      "metadata": {
        "id": "744e0fad-36c1-4f97-ab4d-f236f426a79e"
      },
      "outputs": [],
      "source": [
        "#postprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "2dc8c3c7-4a8b-4a24-97f1-24395817ee58",
      "metadata": {
        "id": "2dc8c3c7-4a8b-4a24-97f1-24395817ee58"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test, prot_train, prot_test = load_gmsc_data_inprocess(csv_path)\n",
        "post_results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "c6803dfb-2800-413d-a8c8-cdba6ec9f0fa",
      "metadata": {
        "id": "c6803dfb-2800-413d-a8c8-cdba6ec9f0fa"
      },
      "outputs": [],
      "source": [
        "def train_roc_postprocessing_with_xgb(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    model = train_baseline_model(X_train, y_train)\n",
        "\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    bld_test = BinaryLabelDataset(\n",
        "        favorable_label=0,\n",
        "        unfavorable_label=1,\n",
        "        df=pd.DataFrame(np.hstack((X_test, y_test[:, None], prot_test[:, None])),\n",
        "                        columns=[f'x{i}' for i in range(X_test.shape[1])] + ['label', 'protected']),\n",
        "        label_names=['label'],\n",
        "        protected_attribute_names=['protected']\n",
        "    )\n",
        "\n",
        "    bld_pred = bld_test.copy()\n",
        "    bld_pred.scores = y_prob.reshape(-1, 1)\n",
        "    bld_pred.labels = y_pred.reshape(-1, 1)\n",
        "\n",
        "    roc = RejectOptionClassification(\n",
        "        unprivileged_groups=[{'protected': 0}],\n",
        "        privileged_groups=[{'protected': 1}],\n",
        "        low_class_thresh=0.3, high_class_thresh=0.7,\n",
        "        num_class_thresh=100, num_ROC_margin=50,\n",
        "        metric_name=\"Statistical parity difference\",\n",
        "        metric_ub=0.05, metric_lb=-0.05\n",
        "    )\n",
        "    roc = roc.fit(bld_test, bld_pred)\n",
        "    pred = roc.predict(bld_pred)\n",
        "\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "2168c0aa-76fc-4f6c-b372-08a5ef4fa88d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2168c0aa-76fc-4f6c-b372-08a5ef4fa88d",
        "outputId": "7e73ac11-fde4-428f-f8f6-3f78d33e444d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:56:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "post_results['RejectOptionClassification'] = train_roc_postprocessing_with_xgb(X_train, y_train, prot_train, X_test, y_test, prot_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "4eadcdcb-e48d-4193-9aa4-d24ce7188caa",
      "metadata": {
        "id": "4eadcdcb-e48d-4193-9aa4-d24ce7188caa"
      },
      "outputs": [],
      "source": [
        "def train_calibrated_eq_odds_with_xgb(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    model = train_baseline_model(X_train, y_train)\n",
        "\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    bld_test = BinaryLabelDataset(\n",
        "        favorable_label=0,\n",
        "        unfavorable_label=1,\n",
        "        df=pd.DataFrame(np.hstack((X_test, y_test[:, None], prot_test[:, None])),\n",
        "                        columns=[f'x{i}' for i in range(X_test.shape[1])] + ['label', 'protected']),\n",
        "        label_names=['label'],\n",
        "        protected_attribute_names=['protected']\n",
        "    )\n",
        "\n",
        "    bld_pred = bld_test.copy()\n",
        "    bld_pred.scores = y_prob.reshape(-1, 1)\n",
        "\n",
        "    ceo = CalibratedEqOddsPostprocessing(\n",
        "        privileged_groups=[{'protected': 1}],\n",
        "        unprivileged_groups=[{'protected': 0}],\n",
        "        cost_constraint=\"fnr\",\n",
        "        seed=42\n",
        "    )\n",
        "    ceo = ceo.fit(bld_test, bld_pred)\n",
        "    pred = ceo.predict(bld_pred)\n",
        "\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "81017dda-febe-495f-8915-89f7128033fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81017dda-febe-495f-8915-89f7128033fc",
        "outputId": "89b1179c-3b00-4fc4-ec11-5067c851f0e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:57:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "post_results['CalibratedEqOdds'] = train_calibrated_eq_odds_with_xgb(X_train, y_train, prot_train, X_test, y_test, prot_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "9a827471-94d8-4b11-a63a-2fc7c2f707b3",
      "metadata": {
        "id": "9a827471-94d8-4b11-a63a-2fc7c2f707b3"
      },
      "outputs": [],
      "source": [
        "def train_equalized_odds_with_xgb(X_train, y_train, prot_train, X_test, y_test, prot_test):\n",
        "    model = train_baseline_model(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    bld_test = BinaryLabelDataset(\n",
        "        favorable_label=0,\n",
        "        unfavorable_label=1,\n",
        "        df=pd.DataFrame(np.hstack((X_test, y_test[:, None], prot_test[:, None])),\n",
        "                        columns=[f'x{i}' for i in range(X_test.shape[1])] + ['label', 'protected']),\n",
        "        label_names=['label'],\n",
        "        protected_attribute_names=['protected']\n",
        "    )\n",
        "\n",
        "    bld_pred = bld_test.copy()\n",
        "    bld_pred.labels = y_pred.reshape(-1, 1)\n",
        "\n",
        "    eq = EqOddsPostprocessing(\n",
        "        privileged_groups=[{'protected': 1}],\n",
        "        unprivileged_groups=[{'protected': 0}]\n",
        "    )\n",
        "    eq = eq.fit(bld_test, bld_pred)\n",
        "    pred = eq.predict(bld_pred)\n",
        "\n",
        "    return evaluate_fairness(y_test, pred.labels.ravel(), prot_test, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "b2e0ecea-dbc8-41a9-a4e9-2b700de1f1f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2e0ecea-dbc8-41a9-a4e9-2b700de1f1f6",
        "outputId": "0d31b8f1-4492-4c7f-8fbc-7bc951dea41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:57:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "post_results['EqualizedOdds'] = train_equalized_odds_with_xgb(X_train, y_train, prot_train, X_test, y_test, prot_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "1e8776c5-6a02-4ab7-a425-34b2abafc1ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e8776c5-6a02-4ab7-a425-34b2abafc1ce",
        "outputId": "a797a499-d779-4edd-a47c-b287c41780ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 RejectOptionClassification\n",
            "  accuracy: 0.0669\n",
            "  disparate_impact: 2119.6431\n",
            "  statistical_parity_difference: 0.0477\n",
            "  equal_opportunity_difference: 0.0301\n",
            "\n",
            "🔹 CalibratedEqOdds\n",
            "  accuracy: 0.0646\n",
            "  disparate_impact: 1.2066\n",
            "  statistical_parity_difference: 0.0048\n",
            "  equal_opportunity_difference: 0.0027\n",
            "\n",
            "🔹 EqualizedOdds\n",
            "  accuracy: 0.9289\n",
            "  disparate_impact: 0.9935\n",
            "  statistical_parity_difference: -0.0064\n",
            "  equal_opportunity_difference: -0.0000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for model, metrics in post_results.items():\n",
        "    print(f\"🔹 {model}\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IbddJ_jw1Lkb"
      },
      "id": "IbddJ_jw1Lkb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}